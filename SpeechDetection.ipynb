{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nabilneal/DataScience/blob/main/SpeechDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3af6cc4",
      "metadata": {
        "id": "a3af6cc4"
      },
      "outputs": [],
      "source": [
        "import sys, os\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "import re\n",
        "pd.options.display.max_colwidth = 150 ###\n",
        "file1 = r\"share/racism.json\"\n",
        "file2 = r\"share/sexism.json\"\n",
        "file3 = r\"share/neither.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60af8524",
      "metadata": {
        "id": "60af8524",
        "outputId": "281abf5e-1a27-47e0-d199-a255f40357dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Started Reading JSON file which contains multiple JSON document\n",
            "Printing each JSON Decoded Object\n",
            "11501 27\n",
            "{'in_reply_to_user_id': None, 'id_str': '569363477095174145', 'is_quote_status': False, 'text': 'RT @TheMeninism: üòÇ http://t.co/VQzuAXqNzd', 'coordinates': None, 'in_reply_to_status_id': None, 'retweeted_status': {'in_reply_to_user_id': None, 'id_str': '569361442455101440', 'is_quote_status': False, 'text': 'üòÇ http://t.co/VQzuAXqNzd', 'coordinates': None, 'lang': 'und', 'in_reply_to_status_id': None, 'retweeted': False, 'retweet_count': 260, 'created_at': 'Sun Feb 22 05:02:00 +0000 2015', 'geo': None, 'extended_entities': {'media': [{'media_url_https': 'https://pbs.twimg.com/media/B-bHNxwIMAAKqld.jpg', 'type': 'photo', 'id_str': '569361442416373760', 'sizes': {'large': {'w': 599, 'resize': 'fit', 'h': 336}, 'thumb': {'w': 150, 'resize': 'crop', 'h': 150}, 'medium': {'w': 599, 'resize': 'fit', 'h': 336}, 'small': {'w': 340, 'resize': 'fit', 'h': 190}}, 'url': 'http://t.co/VQzuAXqNzd', 'media_url': 'http://pbs.twimg.com/media/B-bHNxwIMAAKqld.jpg', 'id': 569361442416373760, 'indices': [2, 24], 'display_url': 'pic.twitter.com/VQzuAXqNzd', 'expanded_url': 'http://twitter.com/TheMeninism/status/569361442455101440/photo/1'}]}, 'place': None, 'truncated': False, 'favorite_count': 514, 'entities': {'user_mentions': [], 'symbols': [], 'urls': [], 'hashtags': [], 'media': [{'media_url_https': 'https://pbs.twimg.com/media/B-bHNxwIMAAKqld.jpg', 'type': 'photo', 'id_str': '569361442416373760', 'sizes': {'large': {'w': 599, 'resize': 'fit', 'h': 336}, 'thumb': {'w': 150, 'resize': 'crop', 'h': 150}, 'medium': {'w': 599, 'resize': 'fit', 'h': 336}, 'small': {'w': 340, 'resize': 'fit', 'h': 190}}, 'url': 'http://t.co/VQzuAXqNzd', 'media_url': 'http://pbs.twimg.com/media/B-bHNxwIMAAKqld.jpg', 'id': 569361442416373760, 'indices': [2, 24], 'display_url': 'pic.twitter.com/VQzuAXqNzd', 'expanded_url': 'http://twitter.com/TheMeninism/status/569361442455101440/photo/1'}]}, 'contributors': None, 'favorited': False, 'source': '<a href=\"http://bufferapp.com\" rel=\"nofollow\">Buffer</a>', 'possibly_sensitive': False, 'in_reply_to_user_id_str': None, 'id': 569361442455101440, 'in_reply_to_status_id_str': None, 'in_reply_to_screen_name': None, 'user': {'profile_sidebar_border_color': 'C0DEED', 'notifications': False, 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/684554398316408835/a0H05BiF_normal.jpg', 'profile_background_color': 'C0DEED', 'listed_count': 189, 'profile_use_background_image': True, 'protected': False, 'url': None, 'follow_request_sent': False, 'profile_text_color': '333333', 'profile_sidebar_fill_color': 'DDEEF6', 'following': False, 'verified': False, 'screen_name': 'TheMeninism', 'is_translation_enabled': False, 'friends_count': 66676, 'geo_enabled': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/684554398316408835/a0H05BiF_normal.jpg', 'created_at': 'Tue Feb 18 21:54:12 +0000 2014', 'contributors_enabled': False, 'lang': 'en', 'profile_link_color': '0084B4', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png', 'has_extended_profile': False, 'statuses_count': 3393, 'profile_background_tile': False, 'entities': {'description': {'urls': []}}, 'utc_offset': -28800, 'name': 'Meninist', 'description': '(parody) obviously sarcasm | contact: meninistbusiness@gmail.com | instagram: iamthemeninist', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/2350727587/1415760735', 'default_profile': True, 'followers_count': 164913, 'id_str': '2350727587', 'favourites_count': 10, 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png', 'is_translator': False, 'time_zone': 'Pacific Time (US & Canada)', 'id': 2350727587, 'default_profile_image': False, 'location': 'Snapchat: DailyMeninist'}}, 'geo': None, 'retweeted': False, 'retweet_count': 260, 'created_at': 'Sun Feb 22 05:10:05 +0000 2015', 'lang': 'und', 'extended_entities': {'media': [{'source_user_id_str': '2350727587', 'media_url_https': 'https://pbs.twimg.com/media/B-bHNxwIMAAKqld.jpg', 'type': 'photo', 'id_str': '569361442416373760', 'source_user_id': 2350727587, 'url': 'http://t.co/VQzuAXqNzd', 'source_status_id_str': '569361442455101440', 'sizes': {'large': {'w': 599, 'resize': 'fit', 'h': 336}, 'thumb': {'w': 150, 'resize': 'crop', 'h': 150}, 'medium': {'w': 599, 'resize': 'fit', 'h': 336}, 'small': {'w': 340, 'resize': 'fit', 'h': 190}}, 'indices': [19, 41], 'expanded_url': 'http://twitter.com/TheMeninism/status/569361442455101440/photo/1', 'source_status_id': 569361442455101440, 'media_url': 'http://pbs.twimg.com/media/B-bHNxwIMAAKqld.jpg', 'id': 569361442416373760, 'display_url': 'pic.twitter.com/VQzuAXqNzd'}]}, 'place': None, 'id': 569363477095174145, 'favorite_count': 0, 'Annotation': 'none', 'entities': {'user_mentions': [{'name': 'Meninist', 'id': 2350727587, 'screen_name': 'TheMeninism', 'indices': [3, 15], 'id_str': '2350727587'}], 'symbols': [], 'urls': [], 'hashtags': [], 'media': [{'source_user_id_str': '2350727587', 'media_url_https': 'https://pbs.twimg.com/media/B-bHNxwIMAAKqld.jpg', 'type': 'photo', 'id_str': '569361442416373760', 'source_user_id': 2350727587, 'url': 'http://t.co/VQzuAXqNzd', 'source_status_id_str': '569361442455101440', 'sizes': {'large': {'w': 599, 'resize': 'fit', 'h': 336}, 'thumb': {'w': 150, 'resize': 'crop', 'h': 150}, 'medium': {'w': 599, 'resize': 'fit', 'h': 336}, 'small': {'w': 340, 'resize': 'fit', 'h': 190}}, 'indices': [19, 41], 'expanded_url': 'http://twitter.com/TheMeninism/status/569361442455101440/photo/1', 'source_status_id': 569361442455101440, 'media_url': 'http://pbs.twimg.com/media/B-bHNxwIMAAKqld.jpg', 'id': 569361442416373760, 'display_url': 'pic.twitter.com/VQzuAXqNzd'}]}, 'contributors': None, 'favorited': False, 'source': '<a href=\"https://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android Tablets</a>', 'possibly_sensitive': False, 'in_reply_to_user_id_str': None, 'truncated': False, 'in_reply_to_status_id_str': None, 'in_reply_to_screen_name': None, 'user': {'profile_sidebar_border_color': 'C0DEED', 'notifications': False, 'protected': False, 'profile_use_background_image': True, 'favourites_count': 19678, 'follow_request_sent': False, 'profile_text_color': '333333', 'profile_sidebar_fill_color': 'DDEEF6', 'following': False, 'verified': False, 'is_translator': False, 'friends_count': 3116, 'contributors_enabled': False, 'lang': 'en', 'id_str': '2756873076', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png', 'profile_image_url': 'http://pbs.twimg.com/profile_images/502960977307267074/36HUHFjw_normal.jpeg', 'profile_link_color': '0084B4', 'entities': {'description': {'urls': []}}, 'utc_offset': None, 'description': 'Human. Equal Rights Advocate. #OpSKYNET #AntiSJW          Honesty is my only excuse.', 'followers_count': 3257, 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png', 'geo_enabled': False, 'screen_name': 'MT8_9', 'profile_background_color': 'C0DEED', 'listed_count': 56, '_id': 2756873076, 'url': None, 'is_translation_enabled': False, 'statuses_count': 20454, 'created_at': 'Fri Aug 22 23:28:35 +0000 2014', 'profile_background_tile': False, 'has_extended_profile': False, 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/502960977307267074/36HUHFjw_normal.jpeg', 'name': 'Male Tears #4648', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/2756873076/1415377130', 'default_profile': True, 'time_zone': None, 'id': 2756873076, 'default_profile_image': False}}\n",
            "['in_reply_to_user_id', 'id_str', 'is_quote_status', 'text', 'coordinates', 'in_reply_to_status_id', 'retweeted_status', 'geo', 'retweeted', 'retweet_count', 'created_at', 'lang', 'extended_entities', 'place', 'id', 'favorite_count', 'Annotation', 'entities', 'contributors', 'favorited', 'source', 'possibly_sensitive', 'in_reply_to_user_id_str', 'truncated', 'in_reply_to_status_id_str', 'in_reply_to_screen_name', 'user']\n"
          ]
        }
      ],
      "source": [
        "tweetList = []\n",
        "print(\"Started Reading JSON file which contains multiple JSON document\")\n",
        "with open(file3) as f:\n",
        "    for jsonObj in f:\n",
        "        tweetDict = json.loads(jsonObj)\n",
        "        tweetList.append(tweetDict)\n",
        "\n",
        "print(\"Printing each JSON Decoded Object\")\n",
        "count = 1\n",
        "print(len(tweetList), len(tweetDict))\n",
        "print(tweetDict)\n",
        "dkeys = []\n",
        "for k in tweetDict:\n",
        "    dkeys.append(k)\n",
        "print(dkeys)\n",
        "# for tweet in tweetList:\n",
        "#     print(count, \" \" , tweet[\"id_str\"])\n",
        "#     count+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a48453b",
      "metadata": {
        "id": "0a48453b"
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_json(file1, lines=True)\n",
        "df2 = pd.read_json(file2, lines=True)\n",
        "df3 = pd.read_json(file3, lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bea6c24b",
      "metadata": {
        "id": "bea6c24b",
        "outputId": "19c03dbb-4aff-4859-a041-7f4c68eac8ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['in_reply_to_screen_name', 'is_quote_status', 'Annotation', 'truncated',\n",
              "       'id', 'place', 'favorite_count', 'favorited', 'retweeted',\n",
              "       'in_reply_to_status_id_str', 'text', 'created_at', 'lang',\n",
              "       'coordinates', 'in_reply_to_user_id', 'user', 'retweet_count',\n",
              "       'in_reply_to_user_id_str', 'in_reply_to_status_id', 'source', 'id_str',\n",
              "       'geo', 'contributors', 'entities', 'possibly_sensitive',\n",
              "       'extended_entities', 'retweeted_status', 'quoted_status_id',\n",
              "       'quoted_status_id_str', 'quoted_status', 'withheld_in_countries'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f973fbc",
      "metadata": {
        "id": "1f973fbc",
        "outputId": "6bc9a5b5-324d-4337-b95f-bbd6a7396205"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1976, 31) (3430, 28) (11501, 32)\n"
          ]
        }
      ],
      "source": [
        "print(df1.shape, df2.shape, df3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "355b2e42",
      "metadata": {
        "id": "355b2e42",
        "outputId": "3b8927e9-ca46-4610-80f9-2a777bc83e5c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Annotation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Someone is going home #mkr ...that obviously cannot cook !</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>They didn't even wash the chicken üò© #MKR</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#MKR Is honestly so fucking staged. The most over rated show after #ImACelebrityAU #MKR2015</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Can someone smash that bottle of Rose &amp;amp; Lime Cordial over Drasko's head please #MKR</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Will someone pls assist Colin in the washing of his hair. Sorry Colin, big fan but pls... Some shampoo mate! #mkr</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11496</th>\n",
              "      <td>RT @JakeM_1998: RT BillSpindle: It's all about power at the top, but for fighters on the ground #Tikrit is religious war on both sides ‚Ä¶</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11497</th>\n",
              "      <td>RT @ThinkAgain_DOS: Iraq: #ISIS sets off 21 car bombs in Anbar ‚Äì as usual, randomly killing &amp;amp; maiming innocents. http://t.co/gufa754CRT htt‚Ä¶</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11498</th>\n",
              "      <td>RT @ThePatriot143: DEAR STATE DEPARTMENT: WHERE IS HILLARY CLINTON‚ÄôS OF-109 FORM http://t.co/aNkzFa5iVP #HillaryEmail #tcot #PJNET http://t‚Ä¶</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11499</th>\n",
              "      <td>\"@panelrific: Let's go üêßüêßüêßüêßüêßüêßüòÉ\"</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11500</th>\n",
              "      <td>RT @TheMeninism: üòÇ http://t.co/VQzuAXqNzd</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11501 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                   text  \\\n",
              "0                                                                                            Someone is going home #mkr ...that obviously cannot cook !   \n",
              "1                                                                                                              They didn't even wash the chicken üò© #MKR   \n",
              "2                                                           #MKR Is honestly so fucking staged. The most over rated show after #ImACelebrityAU #MKR2015   \n",
              "3                                                               Can someone smash that bottle of Rose &amp; Lime Cordial over Drasko's head please #MKR   \n",
              "4                                     Will someone pls assist Colin in the washing of his hair. Sorry Colin, big fan but pls... Some shampoo mate! #mkr   \n",
              "...                                                                                                                                                 ...   \n",
              "11496          RT @JakeM_1998: RT BillSpindle: It's all about power at the top, but for fighters on the ground #Tikrit is religious war on both sides ‚Ä¶   \n",
              "11497  RT @ThinkAgain_DOS: Iraq: #ISIS sets off 21 car bombs in Anbar ‚Äì as usual, randomly killing &amp; maiming innocents. http://t.co/gufa754CRT htt‚Ä¶   \n",
              "11498      RT @ThePatriot143: DEAR STATE DEPARTMENT: WHERE IS HILLARY CLINTON‚ÄôS OF-109 FORM http://t.co/aNkzFa5iVP #HillaryEmail #tcot #PJNET http://t‚Ä¶   \n",
              "11499                                                                                                                   \"@panelrific: Let's go üêßüêßüêßüêßüêßüêßüòÉ\"   \n",
              "11500                                                                                                         RT @TheMeninism: üòÇ http://t.co/VQzuAXqNzd   \n",
              "\n",
              "      Annotation  \n",
              "0           none  \n",
              "1           none  \n",
              "2           none  \n",
              "3           none  \n",
              "4           none  \n",
              "...          ...  \n",
              "11496       none  \n",
              "11497       none  \n",
              "11498       none  \n",
              "11499       none  \n",
              "11500       none  \n",
              "\n",
              "[11501 rows x 2 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1_copy = df1[['text', 'Annotation']]\n",
        "df2_copy = df2[['text', 'Annotation']]\n",
        "df3_copy = df3[['text', 'Annotation']]\n",
        "\n",
        "df3_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4f280b7",
      "metadata": {
        "id": "f4f280b7",
        "outputId": "5cdcdc23-61f1-4115-b693-198fcb35e27b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Annotation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So Drasko just said he was impressed the girls cooked half a chicken.. They cooked a whole one  #MKR</td>\n",
              "      <td>racism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Drasko they didn't cook half a bird you idiot #mkr</td>\n",
              "      <td>racism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hopefully someone cooks Drasko in the next ep of #MKR</td>\n",
              "      <td>racism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>of course you were born in serbia...you're as fucked as A Serbian Film #MKR</td>\n",
              "      <td>racism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>These girls are the equivalent of the irritating Asian girls a couple years ago. Well done, 7. #MKR</td>\n",
              "      <td>racism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1971</th>\n",
              "      <td>Drasko they didn't cook half a bird you idiot #mkr</td>\n",
              "      <td>racism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1972</th>\n",
              "      <td>Hopefully someone cooks Drasko in the next ep of #MKR</td>\n",
              "      <td>racism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1973</th>\n",
              "      <td>#MKR  Lost the plot - where's the big Texan with the elephant sized steaks that they all have for brekkie ?</td>\n",
              "      <td>racism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1974</th>\n",
              "      <td>RT @Benfrancisallen: It hasn't been a good few weeks for #ISIS. A new front has opened up in #Sinjar and they're about to lose the battle f‚Ä¶</td>\n",
              "      <td>racism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1975</th>\n",
              "      <td>RT @TIME: 'Charlie Hebdo' editor killed in Paris terror attack built career on defiance http://t.co/zE8yO2E0W1</td>\n",
              "      <td>racism</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1976 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                              text  \\\n",
              "0                                             So Drasko just said he was impressed the girls cooked half a chicken.. They cooked a whole one  #MKR   \n",
              "1                                                                                               Drasko they didn't cook half a bird you idiot #mkr   \n",
              "2                                                                                            Hopefully someone cooks Drasko in the next ep of #MKR   \n",
              "3                                                                      of course you were born in serbia...you're as fucked as A Serbian Film #MKR   \n",
              "4                                              These girls are the equivalent of the irritating Asian girls a couple years ago. Well done, 7. #MKR   \n",
              "...                                                                                                                                            ...   \n",
              "1971                                                                                            Drasko they didn't cook half a bird you idiot #mkr   \n",
              "1972                                                                                         Hopefully someone cooks Drasko in the next ep of #MKR   \n",
              "1973                                   #MKR  Lost the plot - where's the big Texan with the elephant sized steaks that they all have for brekkie ?   \n",
              "1974  RT @Benfrancisallen: It hasn't been a good few weeks for #ISIS. A new front has opened up in #Sinjar and they're about to lose the battle f‚Ä¶   \n",
              "1975                                RT @TIME: 'Charlie Hebdo' editor killed in Paris terror attack built career on defiance http://t.co/zE8yO2E0W1   \n",
              "\n",
              "     Annotation  \n",
              "0        racism  \n",
              "1        racism  \n",
              "2        racism  \n",
              "3        racism  \n",
              "4        racism  \n",
              "...         ...  \n",
              "1971     racism  \n",
              "1972     racism  \n",
              "1973     racism  \n",
              "1974     racism  \n",
              "1975     racism  \n",
              "\n",
              "[1976 rows x 2 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ba14b6c",
      "metadata": {
        "id": "6ba14b6c",
        "outputId": "c4670289-74bc-4707-df96-bcd0dd75cc1d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\nabil\\AppData\\Local\\Temp\\ipykernel_24224\\422730061.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  dataframe['text'] = dataframe['text'].str.replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ')\n",
            "C:\\Users\\nabil\\AppData\\Local\\Temp\\ipykernel_24224\\422730061.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataframe['text'] = dataframe['text'].str.replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ')\n",
            "C:\\Users\\nabil\\AppData\\Local\\Temp\\ipykernel_24224\\422730061.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataframe['text'] = dataframe['text'].str.replace('RT', ' ')\n",
            "C:\\Users\\nabil\\AppData\\Local\\Temp\\ipykernel_24224\\422730061.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  dataframe['text'] = dataframe['text'].str.replace('@(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ')\n",
            "C:\\Users\\nabil\\AppData\\Local\\Temp\\ipykernel_24224\\422730061.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataframe['text'] = dataframe['text'].str.replace('@(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ')\n",
            "C:\\Users\\nabil\\AppData\\Local\\Temp\\ipykernel_24224\\422730061.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  dataframe['text'] = dataframe['text'].str.replace('[^\\w\\s#@/:%.,_-]', ' ')\n",
            "C:\\Users\\nabil\\AppData\\Local\\Temp\\ipykernel_24224\\422730061.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataframe['text'] = dataframe['text'].str.replace('[^\\w\\s#@/:%.,_-]', ' ')\n",
            "C:\\Users\\nabil\\AppData\\Local\\Temp\\ipykernel_24224\\422730061.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataframe['Annotation'] = dataframe['Annotation'].str.replace('racism', '0')\n",
            "C:\\Users\\nabil\\AppData\\Local\\Temp\\ipykernel_24224\\422730061.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataframe['Annotation'] = dataframe['Annotation'].str.replace('sexism', '1')\n",
            "C:\\Users\\nabil\\AppData\\Local\\Temp\\ipykernel_24224\\422730061.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataframe['Annotation'] = dataframe['Annotation'].str.replace('none', '2')\n"
          ]
        }
      ],
      "source": [
        "def clean_data(dataframe):\n",
        "#replace URL of a text\n",
        "    dataframe['text'] = dataframe['text'].str.replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ')\n",
        "    dataframe['text'] = dataframe['text'].str.replace('RT', ' ')\n",
        "    dataframe['text'] = dataframe['text'].str.replace('@(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ')\n",
        "    dataframe['text'] = dataframe['text'].str.replace('[^\\w\\s#@/:%.,_-]', ' ')\n",
        "    dataframe['Annotation'] = dataframe['Annotation'].str.replace('racism', '0')\n",
        "    dataframe['Annotation'] = dataframe['Annotation'].str.replace('sexism', '1')\n",
        "    dataframe['Annotation'] = dataframe['Annotation'].str.replace('none', '2')\n",
        "clean_data(df1_copy)\n",
        "clean_data(df2_copy)\n",
        "clean_data(df3_copy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7004dc94",
      "metadata": {
        "id": "7004dc94"
      },
      "outputs": [],
      "source": [
        "df_rows = pd.concat([df1_copy, df2_copy], ignore_index=True)\n",
        "df_final = pd.concat([df_rows, df3_copy], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bffc4332",
      "metadata": {
        "id": "bffc4332",
        "outputId": "632b80ce-9bd9-4d49-a337-e846a2be38d9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Annotation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So Drasko just said he was impressed the girls cooked half a chicken.. They cooked a whole one  #MKR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Drasko they didn t cook half a bird you idiot #mkr</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hopefully someone cooks Drasko in the next ep of #MKR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>of course you were born in serbia...you re as fucked as A Serbian Film #MKR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>These girls are the equivalent of the irritating Asian girls a couple years ago. Well done, 7. #MKR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16902</th>\n",
              "      <td>BillSpindle: It s all about power at the top, but for fighters on the ground #Tikrit is religious war on both sides</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16903</th>\n",
              "      <td>Iraq: #ISIS sets off 21 car bombs in Anbar   as usual, randomly killing  amp  maiming innocents.   htt</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16904</th>\n",
              "      <td>DEAR STATE DEPA MENT: WHERE IS HILLARY CLINTON S OF-109 FORM   #HillaryEmail #tcot #PJNET</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16905</th>\n",
              "      <td>Let s go</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16906</th>\n",
              "      <td></td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16907 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                              text  \\\n",
              "0                             So Drasko just said he was impressed the girls cooked half a chicken.. They cooked a whole one  #MKR   \n",
              "1                                                                               Drasko they didn t cook half a bird you idiot #mkr   \n",
              "2                                                                            Hopefully someone cooks Drasko in the next ep of #MKR   \n",
              "3                                                      of course you were born in serbia...you re as fucked as A Serbian Film #MKR   \n",
              "4                              These girls are the equivalent of the irritating Asian girls a couple years ago. Well done, 7. #MKR   \n",
              "...                                                                                                                            ...   \n",
              "16902        BillSpindle: It s all about power at the top, but for fighters on the ground #Tikrit is religious war on both sides     \n",
              "16903                      Iraq: #ISIS sets off 21 car bombs in Anbar   as usual, randomly killing  amp  maiming innocents.   htt    \n",
              "16904                                 DEAR STATE DEPA MENT: WHERE IS HILLARY CLINTON S OF-109 FORM   #HillaryEmail #tcot #PJNET      \n",
              "16905                                                                                                            Let s go            \n",
              "16906                                                                                                                                \n",
              "\n",
              "      Annotation  \n",
              "0              0  \n",
              "1              0  \n",
              "2              0  \n",
              "3              0  \n",
              "4              0  \n",
              "...          ...  \n",
              "16902          2  \n",
              "16903          2  \n",
              "16904          2  \n",
              "16905          2  \n",
              "16906          2  \n",
              "\n",
              "[16907 rows x 2 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23be5799",
      "metadata": {
        "id": "23be5799"
      },
      "outputs": [],
      "source": [
        "from time import time\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# test_df= df_final.sample(frac=0.25,random_state=1)\n",
        "# training_df = df_final.drop(test_df.index)\n",
        "# test_df\n",
        "# training_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d75ae23d",
      "metadata": {
        "id": "d75ae23d"
      },
      "outputs": [],
      "source": [
        "# train_X = training_df['text']\n",
        "# train_y = training_df['Annotation']\n",
        "# test_X = test_df['text']\n",
        "# test_y = test_df['Annotation']\n",
        "\n",
        "train_X,test_X, train_y, test_y = train_test_split(df_final['text'], df_final['Annotation'],\n",
        "                                                   test_size = 0.2, random_state = 10, stratify = df_final['Annotation'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ae00397",
      "metadata": {
        "id": "3ae00397",
        "outputId": "1f40bf1e-965a-4b81-a91d-7c73ace51846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time taken to extract features from training data : 0.801957 seconds\n",
            "n_samples: 13525, n_features: 135916\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\nabil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "t = time()\n",
        "# tf:\n",
        "# tfidf_vectorizer = CountVectorizer()\n",
        "\n",
        "# tfidf:\n",
        "# tfidf_vectorizer = TfidfVectorizer(sublinear_tf = True, max_df = 0.5, stop_words= 'english')\n",
        "\n",
        "# uni-gram:\n",
        "# tfidf_vectorizer = CountVectorizer(ngram_range=(1,1),token_pattern=r'\\b\\w+\\b', min_df=1)\n",
        "\n",
        "# bi-gram:\n",
        "# tfidf_vectorizer = CountVectorizer(ngram_range=(2,2),token_pattern=r'\\b\\w+\\b', min_df=1)\n",
        "\n",
        "# tri-gram:\n",
        "tfidf_vectorizer = CountVectorizer(ngram_range=(3,3),token_pattern=r'\\b\\w+\\b', min_df=1)\n",
        "\n",
        "# uni-gram & bi-gram:\n",
        "# tfidf_vectorizer = CountVectorizer(ngram_range=(1,2),token_pattern=r'\\b\\w+\\b', min_df=1)\n",
        "\n",
        "# uni-gram,bi-gram & tri-gram:\n",
        "# tfidf_vectorizer = CountVectorizer(ngram_range=(1,3),token_pattern=r'\\b\\w+\\b', min_df=1)\n",
        "\n",
        "\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_X)\n",
        "vocabulary = tfidf_vectorizer.get_feature_names()\n",
        "\n",
        "duration = time() - t\n",
        "print(\"Time taken to extract features from training data : %f seconds\" % (duration))\n",
        "print(\"n_samples: %d, n_features: %d\" % X_train_tfidf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "837c1ef1",
      "metadata": {
        "id": "837c1ef1",
        "outputId": "ec57ff4d-7123-4fda-a1a7-4b6ffbc4cc5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time taken to extract features from test data : 0.061434 seconds\n",
            "n_samples: 3382, n_features: 135916\n"
          ]
        }
      ],
      "source": [
        "t = time()\n",
        "X_test_tfidf = tfidf_vectorizer.transform(test_X)\n",
        "\n",
        "duration = time() - t\n",
        "print(\"Time taken to extract features from test data : %f seconds\" % (duration))\n",
        "print(\"n_samples: %d, n_features: %d\" % X_test_tfidf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e04ccf59",
      "metadata": {
        "id": "e04ccf59",
        "outputId": "0a256798-09c8-45d1-871c-cf031c5ff9e5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0 an hour</th>\n",
              "      <th>0 in their</th>\n",
              "      <th>0 patience for</th>\n",
              "      <th>000 000 bc</th>\n",
              "      <th>000 civilians and</th>\n",
              "      <th>000 has been</th>\n",
              "      <th>000 isis sites</th>\n",
              "      <th>000 islamic terrorist</th>\n",
              "      <th>000 per year</th>\n",
              "      <th>000 s of</th>\n",
              "      <th>...</th>\n",
              "      <th>zombies heading towards</th>\n",
              "      <th>zone please cut</th>\n",
              "      <th>zones are exactly</th>\n",
              "      <th>zones are there</th>\n",
              "      <th>zooming in on</th>\n",
              "      <th>zormixar is strategic</th>\n",
              "      <th>zucchini fritters are</th>\n",
              "      <th>zzzz call me</th>\n",
              "      <th>√† la sqlite</th>\n",
              "      <th>ÿßŸäŸÑŸä ÿßŸäŸÑŸäÿß twi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3377</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3378</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3379</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3380</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3381</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3382 rows √ó 67958 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0 an hour  0 in their  0 patience for  000 000 bc  000 civilians and  \\\n",
              "0             0           0               0           0                  0   \n",
              "1             0           0               0           0                  0   \n",
              "2             0           0               0           0                  0   \n",
              "3             0           0               0           0                  0   \n",
              "4             0           0               0           0                  0   \n",
              "...         ...         ...             ...         ...                ...   \n",
              "3377          0           0               0           0                  0   \n",
              "3378          0           0               0           0                  0   \n",
              "3379          0           0               0           0                  0   \n",
              "3380          0           0               0           0                  0   \n",
              "3381          0           0               0           0                  0   \n",
              "\n",
              "      000 has been  000 isis sites  000 islamic terrorist  000 per year  \\\n",
              "0                0               0                      0             0   \n",
              "1                0               0                      0             0   \n",
              "2                0               0                      0             0   \n",
              "3                0               0                      0             0   \n",
              "4                0               0                      0             0   \n",
              "...            ...             ...                    ...           ...   \n",
              "3377             0               0                      0             0   \n",
              "3378             0               0                      0             0   \n",
              "3379             0               0                      0             0   \n",
              "3380             0               0                      0             0   \n",
              "3381             0               0                      0             0   \n",
              "\n",
              "      000 s of  ...  zombies heading towards  zone please cut  \\\n",
              "0            0  ...                        0                0   \n",
              "1            0  ...                        0                0   \n",
              "2            0  ...                        0                0   \n",
              "3            0  ...                        0                0   \n",
              "4            0  ...                        0                0   \n",
              "...        ...  ...                      ...              ...   \n",
              "3377         0  ...                        0                0   \n",
              "3378         0  ...                        0                0   \n",
              "3379         0  ...                        0                0   \n",
              "3380         0  ...                        0                0   \n",
              "3381         0  ...                        0                0   \n",
              "\n",
              "      zones are exactly  zones are there  zooming in on  \\\n",
              "0                     0                0              0   \n",
              "1                     0                0              0   \n",
              "2                     0                0              0   \n",
              "3                     0                0              0   \n",
              "4                     0                0              0   \n",
              "...                 ...              ...            ...   \n",
              "3377                  0                0              0   \n",
              "3378                  0                0              0   \n",
              "3379                  0                0              0   \n",
              "3380                  0                0              0   \n",
              "3381                  0                0              0   \n",
              "\n",
              "      zormixar is strategic  zucchini fritters are  zzzz call me  √† la sqlite  \\\n",
              "0                         0                      0             0            0   \n",
              "1                         0                      0             0            0   \n",
              "2                         0                      0             0            0   \n",
              "3                         0                      0             0            0   \n",
              "4                         0                      0             0            0   \n",
              "...                     ...                    ...           ...          ...   \n",
              "3377                      0                      0             0            0   \n",
              "3378                      0                      0             0            0   \n",
              "3379                      0                      0             0            0   \n",
              "3380                      0                      0             0            0   \n",
              "3381                      0                      0             0            0   \n",
              "\n",
              "      ÿßŸäŸÑŸä ÿßŸäŸÑŸäÿß twi  \n",
              "0                  0  \n",
              "1                  0  \n",
              "2                  0  \n",
              "3                  0  \n",
              "4                  0  \n",
              "...              ...  \n",
              "3377               0  \n",
              "3378               0  \n",
              "3379               0  \n",
              "3380               0  \n",
              "3381               0  \n",
              "\n",
              "[3382 rows x 67958 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(data=X_test_tfidf.toarray(), columns = vocabulary).iloc[:,0::2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "850e8fe1",
      "metadata": {
        "id": "850e8fe1",
        "outputId": "805530ba-2ac1-4ce8-a982-199dba5c5bc5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0 an hour</th>\n",
              "      <th>0 and shut</th>\n",
              "      <th>0 in their</th>\n",
              "      <th>0 men on</th>\n",
              "      <th>0 patience for</th>\n",
              "      <th>00 on this</th>\n",
              "      <th>000 000 bc</th>\n",
              "      <th>000 children work</th>\n",
              "      <th>000 civilians and</th>\n",
              "      <th>000 foreign recruits</th>\n",
              "      <th>...</th>\n",
              "      <th>zormixar is strategic</th>\n",
              "      <th>zozo strangers that</th>\n",
              "      <th>zucchini fritters are</th>\n",
              "      <th>zynga for being</th>\n",
              "      <th>zzzz call me</th>\n",
              "      <th>¬Ω the weight</th>\n",
              "      <th>√† la sqlite</th>\n",
              "      <th>ÿßŸÑÿ±ÿµÿßŸÅÿ© neighborhood in</th>\n",
              "      <th>ÿßŸäŸÑŸä ÿßŸäŸÑŸäÿß twi</th>\n",
              "      <th>ÿßŸäŸÑŸäÿß twi insta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3375</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3377</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3378</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3379</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3380</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2597 rows √ó 135916 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0 an hour  0 and shut  0 in their  0 men on  0 patience for  00 on this  \\\n",
              "2             0           0           0         0               0           0   \n",
              "4             0           0           0         0               0           0   \n",
              "5             0           0           0         0               0           0   \n",
              "6             0           0           0         0               0           0   \n",
              "7             0           0           0         0               0           0   \n",
              "...         ...         ...         ...       ...             ...         ...   \n",
              "3375          0           0           0         0               0           0   \n",
              "3377          0           0           0         0               0           0   \n",
              "3378          0           0           0         0               0           0   \n",
              "3379          0           0           0         0               0           0   \n",
              "3380          0           0           0         0               0           0   \n",
              "\n",
              "      000 000 bc  000 children work  000 civilians and  000 foreign recruits  \\\n",
              "2              0                  0                  0                     0   \n",
              "4              0                  0                  0                     0   \n",
              "5              0                  0                  0                     0   \n",
              "6              0                  0                  0                     0   \n",
              "7              0                  0                  0                     0   \n",
              "...          ...                ...                ...                   ...   \n",
              "3375           0                  0                  0                     0   \n",
              "3377           0                  0                  0                     0   \n",
              "3378           0                  0                  0                     0   \n",
              "3379           0                  0                  0                     0   \n",
              "3380           0                  0                  0                     0   \n",
              "\n",
              "      ...  zormixar is strategic  zozo strangers that  zucchini fritters are  \\\n",
              "2     ...                      0                    0                      0   \n",
              "4     ...                      0                    0                      0   \n",
              "5     ...                      0                    0                      0   \n",
              "6     ...                      0                    0                      0   \n",
              "7     ...                      0                    0                      0   \n",
              "...   ...                    ...                  ...                    ...   \n",
              "3375  ...                      0                    0                      0   \n",
              "3377  ...                      0                    0                      0   \n",
              "3378  ...                      0                    0                      0   \n",
              "3379  ...                      0                    0                      0   \n",
              "3380  ...                      0                    0                      0   \n",
              "\n",
              "      zynga for being  zzzz call me  ¬Ω the weight  √† la sqlite  \\\n",
              "2                   0             0             0            0   \n",
              "4                   0             0             0            0   \n",
              "5                   0             0             0            0   \n",
              "6                   0             0             0            0   \n",
              "7                   0             0             0            0   \n",
              "...               ...           ...           ...          ...   \n",
              "3375                0             0             0            0   \n",
              "3377                0             0             0            0   \n",
              "3378                0             0             0            0   \n",
              "3379                0             0             0            0   \n",
              "3380                0             0             0            0   \n",
              "\n",
              "      ÿßŸÑÿ±ÿµÿßŸÅÿ© neighborhood in  ÿßŸäŸÑŸä ÿßŸäŸÑŸäÿß twi  ÿßŸäŸÑŸäÿß twi insta  \n",
              "2                           0               0                0  \n",
              "4                           0               0                0  \n",
              "5                           0               0                0  \n",
              "6                           0               0                0  \n",
              "7                           0               0                0  \n",
              "...                       ...             ...              ...  \n",
              "3375                        0               0                0  \n",
              "3377                        0               0                0  \n",
              "3378                        0               0                0  \n",
              "3379                        0               0                0  \n",
              "3380                        0               0                0  \n",
              "\n",
              "[2597 rows x 135916 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = pd.DataFrame(data=X_test_tfidf.toarray(), columns = vocabulary).iloc[:,0::1]\n",
        "x = x[(x > 0).any(axis=1)]\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "977450a3",
      "metadata": {
        "id": "977450a3",
        "outputId": "6c6cf484-9de4-4d61-e454-3c019c5303e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train time: 0.057s\n"
          ]
        }
      ],
      "source": [
        "# build naive bayes classification model\n",
        "t = time()\n",
        "\n",
        "naive_bayes_classifier = MultinomialNB()\n",
        "naive_bayes_classifier.fit(X_train_tfidf, train_y)\n",
        "\n",
        "training_time = time() - t\n",
        "print(\"train time: %0.3fs\" % training_time)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22297085",
      "metadata": {
        "id": "22297085",
        "outputId": "a320383f-29e8-400b-8348-343494917129"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes : \n",
            "\n",
            "accuracy:   0.767\n",
            "precision:   0.752\n",
            "recall:   0.583\n",
            "f1:   0.632\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      racism       0.75      0.40      0.52       395\n",
            "      sexism       0.74      0.42      0.53       686\n",
            "     neither       0.77      0.94      0.85      2301\n",
            "\n",
            "    accuracy                           0.77      3382\n",
            "   macro avg       0.75      0.58      0.63      3382\n",
            "weighted avg       0.76      0.77      0.74      3382\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# predict the new document from the testing dataset\n",
        "print(\"Naive Bayes : \\n\")\n",
        "\n",
        "t = time()\n",
        "y_pred = naive_bayes_classifier.predict(X_test_tfidf)\n",
        "\n",
        "test_time = time() - t\n",
        "# print(\"test time:  %0.3fs\" % test_time)\n",
        "\n",
        "# compute the performance measures\n",
        "score1 = metrics.accuracy_score(test_y, y_pred)\n",
        "score2 = metrics.f1_score(test_y, y_pred,average='macro')\n",
        "score3 = metrics.precision_score(test_y, y_pred, average='macro')\n",
        "score4 = metrics.recall_score(test_y, y_pred, average='macro')\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "print(\"precision:   %0.3f\" % score3)\n",
        "print(\"recall:   %0.3f\" % score4)\n",
        "print(\"f1:   %0.3f\" % score2)\n",
        "\n",
        "print(metrics.classification_report(test_y, y_pred,\n",
        "                                            target_names=['racism', 'sexism', 'neither']))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d6b8b7e",
      "metadata": {
        "id": "7d6b8b7e",
        "outputId": "bef67590-ac3e-4c2c-8e43-7c73027a44c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "Train Accuracy : 0.897\n",
            "Test Accuracy : 0.742\n",
            "Best Accuracy Through Grid Search : 0.741\n",
            "Best Parameters :  {'alpha': 10.0}\n"
          ]
        }
      ],
      "source": [
        "params = {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0]}\n",
        "\n",
        "bernoulli_nb_grid = GridSearchCV(naive_bayes_classifier, param_grid=params, n_jobs=-1, cv=5, verbose=5)\n",
        "bernoulli_nb_grid.fit(X_train_tfidf, train_y)\n",
        "\n",
        "print('Train Accuracy : %.3f'%bernoulli_nb_grid.best_estimator_.score(X_train_tfidf, train_y))\n",
        "print('Test Accuracy : %.3f'%bernoulli_nb_grid.best_estimator_.score(X_test_tfidf, test_y))\n",
        "print('Best Accuracy Through Grid Search : %.3f'%bernoulli_nb_grid.best_score_)\n",
        "print('Best Parameters : ',bernoulli_nb_grid.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c322c39",
      "metadata": {
        "id": "3c322c39"
      },
      "outputs": [],
      "source": [
        "#SVC\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "clf = SVC(C=1.0, kernel='linear', gamma = 'auto').fit(X_train_tfidf, train_y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eea9e69a",
      "metadata": {
        "id": "eea9e69a",
        "outputId": "7413bb22-65d7-4e3e-fd58-a697a4debfc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Support Vector Machine : \n",
            "\n",
            "accuracy:   0.750\n",
            "precision:   0.811\n",
            "recall:   0.486\n",
            "f1:   0.524\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      racism       0.82      0.15      0.26       395\n",
            "      sexism       0.87      0.33      0.47       686\n",
            "     neither       0.74      0.98      0.84      2301\n",
            "\n",
            "    accuracy                           0.75      3382\n",
            "   macro avg       0.81      0.49      0.52      3382\n",
            "weighted avg       0.78      0.75      0.70      3382\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = clf.predict(X_test_tfidf)\n",
        "print(\"Support Vector Machine : \\n\")\n",
        "\n",
        "score1 = metrics.accuracy_score(test_y, y_pred)\n",
        "score2 = metrics.f1_score(test_y, y_pred,average='macro')\n",
        "score3 = metrics.precision_score(test_y, y_pred, average='macro')\n",
        "score4 = metrics.recall_score(test_y, y_pred, average='macro')\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "print(\"precision:   %0.3f\" % score3)\n",
        "print(\"recall:   %0.3f\" % score4)\n",
        "print(\"f1:   %0.3f\" % score2)\n",
        "\n",
        "print(metrics.classification_report(test_y, y_pred,\n",
        "                                            target_names=['racism', 'sexism', 'neither']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db640d1d",
      "metadata": {
        "scrolled": true,
        "id": "db640d1d"
      },
      "outputs": [],
      "source": [
        "# ## TAKES A LONG TIME TO EXECUTE\n",
        "\n",
        "\n",
        "# param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "#               'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "#               'kernel': ['rbf']}\n",
        "\n",
        "# grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        "\n",
        "# # fitting the model for grid search\n",
        "# grid.fit(X_train_tfidf, train_y)\n",
        "\n",
        "# # print best parameter after tuning\n",
        "# print(grid.best_params_)\n",
        "\n",
        "# # print how our model looks after hyper-parameter tuning\n",
        "# print(grid.best_estimator_)\n",
        "\n",
        "# grid_predictions = grid.predict(X_test_tfidf)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9dc5305",
      "metadata": {
        "id": "a9dc5305",
        "outputId": "0f1c6989-97f9-4674-eb26-0fba3ed92177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Support Vector Machine After Grid Search : \n",
            "\n",
            "accuracy:   0.747\n",
            "precision:   0.820\n",
            "recall:   0.474\n",
            "f1:   0.508\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      racism       0.84      0.13      0.22       395\n",
            "      sexism       0.89      0.31      0.46       686\n",
            "     neither       0.73      0.98      0.84      2301\n",
            "\n",
            "    accuracy                           0.75      3382\n",
            "   macro avg       0.82      0.47      0.51      3382\n",
            "weighted avg       0.78      0.75      0.69      3382\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clf = SVC(C=100, kernel='rbf', gamma = 0.001).fit(X_train_tfidf, train_y)\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Support Vector Machine After Grid Search : \\n\")\n",
        "\n",
        "score1 = metrics.accuracy_score(test_y, y_pred)\n",
        "score2 = metrics.f1_score(test_y, y_pred,average='macro')\n",
        "score3 = metrics.precision_score(test_y, y_pred, average='macro')\n",
        "score4 = metrics.recall_score(test_y, y_pred, average='macro')\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "print(\"precision:   %0.3f\" % score3)\n",
        "print(\"recall:   %0.3f\" % score4)\n",
        "print(\"f1:   %0.3f\" % score2)\n",
        "\n",
        "print(metrics.classification_report(test_y, y_pred,\n",
        "                                            target_names=['racism', 'sexism', 'neither']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbb4f667",
      "metadata": {
        "id": "bbb4f667"
      },
      "outputs": [],
      "source": [
        "#Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train_tfidf,train_y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ebe7a5d",
      "metadata": {
        "id": "5ebe7a5d",
        "outputId": "df4f11f0-eb74-4b76-b942-df82e5052533"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree : \n",
            "\n",
            "accuracy:   0.741\n",
            "precision:   0.701\n",
            "recall:   0.525\n",
            "f1:   0.567\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      racism       0.62      0.29      0.40       395\n",
            "      sexism       0.73      0.35      0.47       686\n",
            "     neither       0.75      0.94      0.83      2301\n",
            "\n",
            "    accuracy                           0.74      3382\n",
            "   macro avg       0.70      0.53      0.57      3382\n",
            "weighted avg       0.73      0.74      0.71      3382\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "print(\"Decision Tree : \\n\")\n",
        "\n",
        "score1 = metrics.accuracy_score(test_y, y_pred)\n",
        "score2 = metrics.f1_score(test_y, y_pred,average='macro')\n",
        "score3 = metrics.precision_score(test_y, y_pred, average='macro')\n",
        "score4 = metrics.recall_score(test_y, y_pred, average='macro')\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "print(\"precision:   %0.3f\" % score3)\n",
        "print(\"recall:   %0.3f\" % score4)\n",
        "print(\"f1:   %0.3f\" % score2)\n",
        "\n",
        "print(metrics.classification_report(test_y, y_pred,\n",
        "                                            target_names=['racism', 'sexism', 'neither']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51485c3c",
      "metadata": {
        "id": "51485c3c"
      },
      "outputs": [],
      "source": [
        "# Takes time to execute Grid Search\n",
        "\n",
        "# param_dict = {\"criterion\" : ['gini', 'entropy'],\n",
        "#               \"max_depth\" : range(1,10),\n",
        "#               \"min_samples_split\" : range(1,10),\n",
        "#               \"min_samples_leaf\" : range(1,5)\n",
        "# }\n",
        "\n",
        "# grid = GridSearchCV( DecisionTreeClassifier(), param_grid = param_dict,\n",
        "#                     cv = 10, verbose = 1, n_jobs = -1)\n",
        "\n",
        "# grid.fit(X_train_tfidf,train_y)\n",
        "\n",
        "# print(grid.best_params_)\n",
        "# print(grid.best_estimator_)\n",
        "# print(grid.best_score_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e951d7c9",
      "metadata": {
        "id": "e951d7c9",
        "outputId": "c4a8684b-ee57-4b73-d583-465db80af718"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree After Grid Search: \n",
            "\n",
            "accuracy:   0.738\n",
            "precision:   0.867\n",
            "recall:   0.444\n",
            "f1:   0.465\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      racism       0.92      0.09      0.16       395\n",
            "      sexism       0.96      0.25      0.40       686\n",
            "     neither       0.72      1.00      0.84      2301\n",
            "\n",
            "    accuracy                           0.74      3382\n",
            "   macro avg       0.87      0.44      0.46      3382\n",
            "weighted avg       0.79      0.74      0.67      3382\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# After Grid search: best parameters\n",
        "\n",
        "clf = DecisionTreeClassifier(max_depth=9, min_samples_leaf=3, min_samples_split=8)\n",
        "print(\"Decision Tree After Grid Search: \\n\")\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train_tfidf,train_y)\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "\n",
        "score1 = metrics.accuracy_score(test_y, y_pred)\n",
        "score2 = metrics.f1_score(test_y, y_pred,average='macro')\n",
        "score3 = metrics.precision_score(test_y, y_pred, average='macro')\n",
        "score4 = metrics.recall_score(test_y, y_pred, average='macro')\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "print(\"precision:   %0.3f\" % score3)\n",
        "print(\"recall:   %0.3f\" % score4)\n",
        "print(\"f1:   %0.3f\" % score2)\n",
        "\n",
        "print(metrics.classification_report(test_y, y_pred,\n",
        "                                            target_names=['racism', 'sexism', 'neither']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "589cc048",
      "metadata": {
        "id": "589cc048",
        "outputId": "bc3c4ab6-87c6-4b65-d37a-b8cfe0ffb61d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators = 100)\n",
        "\n",
        "clf.fit(X_train_tfidf, train_y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23d91566",
      "metadata": {
        "id": "23d91566",
        "outputId": "77d07adb-05dd-4b07-ab36-34c0c70245bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Classifier : \n",
            "\n",
            "accuracy:   0.744\n",
            "precision:   0.822\n",
            "recall:   0.475\n",
            "f1:   0.513\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      racism       0.86      0.17      0.29       395\n",
            "      sexism       0.87      0.27      0.41       686\n",
            "     neither       0.73      0.98      0.84      2301\n",
            "\n",
            "    accuracy                           0.74      3382\n",
            "   macro avg       0.82      0.48      0.51      3382\n",
            "weighted avg       0.78      0.74      0.69      3382\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# performing predictions on the test dataset\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "print(\"Random Forest Classifier : \\n\")\n",
        "\n",
        "score1 = metrics.accuracy_score(test_y, y_pred)\n",
        "score2 = metrics.f1_score(test_y, y_pred,average='macro')\n",
        "score3 = metrics.precision_score(test_y, y_pred, average='macro')\n",
        "score4 = metrics.recall_score(test_y, y_pred, average='macro')\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "print(\"precision:   %0.3f\" % score3)\n",
        "print(\"recall:   %0.3f\" % score4)\n",
        "print(\"f1:   %0.3f\" % score2)\n",
        "\n",
        "print(metrics.classification_report(test_y, y_pred,\n",
        "                                            target_names=['racism', 'sexism', 'neither']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "639aedc8",
      "metadata": {
        "id": "639aedc8"
      },
      "outputs": [],
      "source": [
        "# takes a long time to execute Grid Search\n",
        "\n",
        "# param_grid = {\n",
        "#     'n_estimators': [200, 500],\n",
        "#     'max_features': ['auto', 'sqrt', 'log2'],\n",
        "#     'max_depth' : [4,5,6,7,8],\n",
        "#     'criterion' :['gini', 'entropy']\n",
        "# }\n",
        "\n",
        "# CV_rfc = GridSearchCV(estimator=RandomForestClassifier(random_state=42), param_grid=param_grid, cv= 5)\n",
        "# CV_rfc.fit(X_train_tfidf, train_y)\n",
        "# print(CV_rfc.best_params_)\n",
        "# print(CV_rfc.best_estimator_)\n",
        "# print(CV_rfc.best_score_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c00f153b",
      "metadata": {
        "id": "c00f153b",
        "outputId": "f355f520-eb5b-41df-fa2e-1766f57ba0f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Classifier After Grid Search : \n",
            "\n",
            "accuracy:   0.680\n",
            "precision:   0.227\n",
            "recall:   0.333\n",
            "f1:   0.270\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      racism       0.00      0.00      0.00       395\n",
            "      sexism       0.00      0.00      0.00       686\n",
            "     neither       0.68      1.00      0.81      2301\n",
            "\n",
            "    accuracy                           0.68      3382\n",
            "   macro avg       0.23      0.33      0.27      3382\n",
            "weighted avg       0.46      0.68      0.55      3382\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\nabil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\nabil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\nabil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\nabil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "clf = RandomForestClassifier(criterion= 'gini',max_depth=4, n_estimators=200, random_state=42)\n",
        "print(\"Random Forest Classifier After Grid Search : \\n\")\n",
        "\n",
        "clf.fit(X_train_tfidf, train_y)\n",
        "\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "\n",
        "score1 = metrics.accuracy_score(test_y, y_pred)\n",
        "score2 = metrics.f1_score(test_y, y_pred,average='macro')\n",
        "score3 = metrics.precision_score(test_y, y_pred, average='macro')\n",
        "score4 = metrics.recall_score(test_y, y_pred, average='macro')\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "print(\"precision:   %0.3f\" % score3)\n",
        "print(\"recall:   %0.3f\" % score4)\n",
        "print(\"f1:   %0.3f\" % score2)\n",
        "\n",
        "\n",
        "print(metrics.classification_report(test_y, y_pred,\n",
        "                                            target_names=['racism', 'sexism', 'neither']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de50bb85",
      "metadata": {
        "id": "de50bb85",
        "outputId": "b3c83ec6-181f-491c-b6a4-6fed9fcb9d5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# instantiate the model (using the default parameters)\n",
        "logreg = LogisticRegression(max_iter = 1000)\n",
        "\n",
        "# fit the model with data\n",
        "logreg.fit(X_train_tfidf,train_y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27114d8c",
      "metadata": {
        "id": "27114d8c",
        "outputId": "b0836544-86c9-45f7-b0b7-eb9dd9bf4437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression : \n",
            "\n",
            "accuracy:   0.749\n",
            "precision:   0.823\n",
            "recall:   0.476\n",
            "f1:   0.509\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      racism       0.84      0.12      0.21       395\n",
            "      sexism       0.89      0.32      0.47       686\n",
            "     neither       0.74      0.98      0.84      2301\n",
            "\n",
            "    accuracy                           0.75      3382\n",
            "   macro avg       0.82      0.48      0.51      3382\n",
            "weighted avg       0.78      0.75      0.69      3382\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred=logreg.predict(X_test_tfidf)\n",
        "print(\"Logistic Regression : \\n\")\n",
        "\n",
        "score1 = metrics.accuracy_score(test_y, y_pred)\n",
        "score2 = metrics.f1_score(test_y, y_pred,average='macro')\n",
        "score3 = metrics.precision_score(test_y, y_pred, average='macro')\n",
        "score4 = metrics.recall_score(test_y, y_pred, average='macro')\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "print(\"precision:   %0.3f\" % score3)\n",
        "print(\"recall:   %0.3f\" % score4)\n",
        "print(\"f1:   %0.3f\" % score2)\n",
        "\n",
        "print(metrics.classification_report(test_y, y_pred,\n",
        "                                            target_names=['racism', 'sexism', 'neither']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da208c5b",
      "metadata": {
        "id": "da208c5b"
      },
      "outputs": [],
      "source": [
        "# takes a long time to execute Grid Search\n",
        "\n",
        "# grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
        "# logreg=LogisticRegression()\n",
        "# logreg_cv=GridSearchCV(logreg,grid,cv=10)\n",
        "# logreg_cv.fit(X_train_tfidf,train_y)\n",
        "\n",
        "# print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
        "# print(logreg_cv.best_estimator_)\n",
        "# print(\"accuracy :\",logreg_cv.best_score_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c49ec60",
      "metadata": {
        "id": "2c49ec60",
        "outputId": "1d6c4cf7-e872-4eba-8347-c6cc10dfa782"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression After Grid Search: \n",
            "\n",
            "accuracy:   0.752\n",
            "precision:   0.821\n",
            "recall:   0.486\n",
            "f1:   0.525\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      racism       0.84      0.15      0.25       395\n",
            "      sexism       0.88      0.33      0.48       686\n",
            "     neither       0.74      0.98      0.84      2301\n",
            "\n",
            "    accuracy                           0.75      3382\n",
            "   macro avg       0.82      0.49      0.52      3382\n",
            "weighted avg       0.78      0.75      0.70      3382\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clf = LogisticRegression(C=10.0, penalty = 'l2', max_iter = 1000)\n",
        "print(\"Logistic Regression After Grid Search: \\n\")\n",
        "\n",
        "clf.fit(X_train_tfidf, train_y)\n",
        "\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "\n",
        "score1 = metrics.accuracy_score(test_y, y_pred)\n",
        "score2 = metrics.f1_score(test_y, y_pred,average='macro')\n",
        "score3 = metrics.precision_score(test_y, y_pred, average='macro')\n",
        "score4 = metrics.recall_score(test_y, y_pred, average='macro')\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "print(\"precision:   %0.3f\" % score3)\n",
        "print(\"recall:   %0.3f\" % score4)\n",
        "print(\"f1:   %0.3f\" % score2)\n",
        "\n",
        "print(metrics.classification_report(test_y, y_pred,\n",
        "                                            target_names=['racism', 'sexism', 'neither']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf48dec4",
      "metadata": {
        "id": "bf48dec4",
        "outputId": "12969120-f00c-44a3-b68b-7ab144afe243"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=4)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors=4)\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(X_train_tfidf,train_y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3d0b01e",
      "metadata": {
        "id": "f3d0b01e",
        "outputId": "acd70d6e-33e2-41cc-bc85-d01fd9990d5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K Nearest Neighbors : \n",
            "\n",
            "accuracy:   0.687\n",
            "precision:   0.784\n",
            "recall:   0.352\n",
            "f1:   0.310\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      racism       1.00      0.03      0.05       395\n",
            "      sexism       0.67      0.03      0.07       686\n",
            "     neither       0.69      1.00      0.81      2301\n",
            "\n",
            "    accuracy                           0.69      3382\n",
            "   macro avg       0.78      0.35      0.31      3382\n",
            "weighted avg       0.72      0.69      0.57      3382\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\nabil\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test_tfidf)\n",
        "print(\"K Nearest Neighbors : \\n\")\n",
        "\n",
        "score1 = metrics.accuracy_score(test_y, y_pred)\n",
        "score2 = metrics.f1_score(test_y, y_pred,average='macro')\n",
        "score3 = metrics.precision_score(test_y, y_pred, average='macro')\n",
        "score4 = metrics.recall_score(test_y, y_pred, average='macro')\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "print(\"precision:   %0.3f\" % score3)\n",
        "print(\"recall:   %0.3f\" % score4)\n",
        "print(\"f1:   %0.3f\" % score2)\n",
        "\n",
        "print(metrics.classification_report(test_y, y_pred,\n",
        "                                            target_names=['racism', 'sexism', 'neither']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd7657ab",
      "metadata": {
        "id": "cd7657ab"
      },
      "outputs": [],
      "source": [
        "# takes a long time to execute Grid Search\n",
        "\n",
        "# k_range = list(range(1, 31))\n",
        "# param_grid = dict(n_neighbors=k_range)\n",
        "\n",
        "# # defining parameter range\n",
        "# grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=10, scoring='accuracy', return_train_score=False,verbose=1)\n",
        "\n",
        "# # fitting the model for grid search\n",
        "# grid_search=grid.fit(X_train_tfidf,train_y)\n",
        "\n",
        "# print(grid_search.best_params_)\n",
        "# print(grid_search.best_estimator_)\n",
        "# print(grid_search.best_score_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f9146f9",
      "metadata": {
        "id": "3f9146f9",
        "outputId": "7a200d95-3604-41db-edc8-1425a1937d6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K Nearest Neighbors After Grid Search: \n",
            "\n",
            "accuracy:   0.683\n",
            "precision:   0.728\n",
            "recall:   0.342\n",
            "f1:   0.288\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      racism       1.00      0.02      0.04       395\n",
            "      sexism       0.50      0.01      0.01       686\n",
            "     neither       0.68      1.00      0.81      2301\n",
            "\n",
            "    accuracy                           0.68      3382\n",
            "   macro avg       0.73      0.34      0.29      3382\n",
            "weighted avg       0.68      0.68      0.56      3382\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\nabil\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
          ]
        }
      ],
      "source": [
        "model = KNeighborsClassifier(n_neighbors=6)\n",
        "print(\"K Nearest Neighbors After Grid Search: \\n\")\n",
        "\n",
        "model.fit(X_train_tfidf, train_y)\n",
        "\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "score1 = metrics.accuracy_score(test_y, y_pred)\n",
        "score2 = metrics.f1_score(test_y, y_pred,average='macro')\n",
        "score3 = metrics.precision_score(test_y, y_pred, average='macro')\n",
        "score4 = metrics.recall_score(test_y, y_pred, average='macro')\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "print(\"precision:   %0.3f\" % score3)\n",
        "print(\"recall:   %0.3f\" % score4)\n",
        "print(\"f1:   %0.3f\" % score2)\n",
        "\n",
        "print(metrics.classification_report(test_y, y_pred,\n",
        "                                            target_names=['racism', 'sexism', 'neither']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5da731b2",
      "metadata": {
        "id": "5da731b2"
      },
      "source": [
        "# UNDERSAMPLED DATA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "374593e5",
      "metadata": {
        "id": "374593e5",
        "outputId": "c14ac48f-d721-4c4a-fb86-c0b27507d172"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2    11501\n",
              "1     3430\n",
              "0     1976\n",
              "Name: Annotation, dtype: int64"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final[\"Annotation\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfd8991c",
      "metadata": {
        "id": "cfd8991c"
      },
      "outputs": [],
      "source": [
        "class_3,class_2,class_1 = df_final.Annotation.value_counts()\n",
        "c3 = df_final[df_final['Annotation'] == '2']\n",
        "c2 = df_final[df_final['Annotation'] == '1']\n",
        "c1 = df_final[df_final['Annotation'] == '0']\n",
        "df_3 = c3.sample(class_1)\n",
        "df_2 = c2.sample(class_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b0eba43",
      "metadata": {
        "id": "2b0eba43"
      },
      "outputs": [],
      "source": [
        "undersampled_df = pd.concat([df_3,df_2,c1],axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a415c169",
      "metadata": {
        "id": "a415c169",
        "outputId": "f00719ae-fa6d-4bfe-a292-dfa8178bd3dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2    1976\n",
              "1    1976\n",
              "0    1976\n",
              "Name: Annotation, dtype: int64"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "undersampled_df[\"Annotation\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "491a4abd",
      "metadata": {
        "id": "491a4abd"
      },
      "outputs": [],
      "source": [
        "train_X,test_X, train_y, test_y = train_test_split(undersampled_df['text'], undersampled_df['Annotation'],\n",
        "                                                   test_size = 0.2, random_state = 10, stratify = undersampled_df['Annotation'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f53b3f35",
      "metadata": {
        "id": "f53b3f35",
        "outputId": "69630198-fc20-462d-9158-37f58f9a9777"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time taken to extract features from training data : 0.486571 seconds\n",
            "n_samples: 4742, n_features: 100952\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\nabil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "t = time()\n",
        "# tf:\n",
        "# tfidf_vectorizer = CountVectorizer()\n",
        "\n",
        "# tfidf:\n",
        "# tfidf_vectorizer = TfidfVectorizer(sublinear_tf = True, max_df = 0.5, stop_words= 'english')\n",
        "\n",
        "# uni-gram:\n",
        "# tfidf_vectorizer = CountVectorizer(ngram_range=(1,1),token_pattern=r'\\b\\w+\\b', min_df=1)\n",
        "\n",
        "# bi-gram:\n",
        "# tfidf_vectorizer = CountVectorizer(ngram_range=(2,2),token_pattern=r'\\b\\w+\\b', min_df=1)\n",
        "\n",
        "# tri-gram:\n",
        "# tfidf_vectorizer = CountVectorizer(ngram_range=(3,3),token_pattern=r'\\b\\w+\\b', min_df=1)\n",
        "\n",
        "# uni-gram & bi-gram:\n",
        "# tfidf_vectorizer = CountVectorizer(ngram_range=(1,2),token_pattern=r'\\b\\w+\\b', min_df=1)\n",
        "\n",
        "# uni-gram,bi-gram & tri-gram:\n",
        "tfidf_vectorizer = CountVectorizer(ngram_range=(1,3),token_pattern=r'\\b\\w+\\b', min_df=1)\n",
        "\n",
        "\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_X)\n",
        "vocabulary = tfidf_vectorizer.get_feature_names()\n",
        "\n",
        "duration = time() - t\n",
        "print(\"Time taken to extract features from training data : %f seconds\" % (duration))\n",
        "print(\"n_samples: %d, n_features: %d\" % X_train_tfidf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44e77a9b",
      "metadata": {
        "id": "44e77a9b",
        "outputId": "b0f30f46-ebc3-47d7-edf5-66288afd9205"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time taken to extract features from test data : 0.039909 seconds\n",
            "n_samples: 1186, n_features: 100952\n"
          ]
        }
      ],
      "source": [
        "t = time()\n",
        "X_test_tfidf = tfidf_vectorizer.transform(test_X)\n",
        "\n",
        "duration = time() - t\n",
        "print(\"Time taken to extract features from test data : %f seconds\" % (duration))\n",
        "print(\"n_samples: %d, n_features: %d\" % X_test_tfidf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc7ef2de",
      "metadata": {
        "id": "fc7ef2de",
        "outputId": "5ad42e8e-0848-4b5d-b011-fbc06ccdc7e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train time: 0.016s\n"
          ]
        }
      ],
      "source": [
        "t = time()\n",
        "\n",
        "naive_bayes_classifier = MultinomialNB()\n",
        "naive_bayes_classifier.fit(X_train_tfidf, train_y)\n",
        "\n",
        "training_time = time() - t\n",
        "print(\"train time: %0.3fs\" % training_time)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "199d4ac0",
      "metadata": {
        "id": "199d4ac0",
        "outputId": "c3b574a3-552e-4fe5-e40f-d195e3cd6137"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes : \n",
            "\n",
            "accuracy:   0.759\n",
            "precision:   0.759\n",
            "recall:   0.759\n",
            "f1:   0.747\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      racism       0.76      0.94      0.84       395\n",
            "      sexism       0.76      0.82      0.79       396\n",
            "     neither       0.76      0.51      0.61       395\n",
            "\n",
            "    accuracy                           0.76      1186\n",
            "   macro avg       0.76      0.76      0.75      1186\n",
            "weighted avg       0.76      0.76      0.75      1186\n",
            "\n"
          ]
        }
      ],
      "source": [
        "t = time()\n",
        "y_pred = naive_bayes_classifier.predict(X_test_tfidf)\n",
        "print(\"Naive Bayes : \\n\")\n",
        "\n",
        "test_time = time() - t\n",
        "# print(\"test time:  %0.3fs\" % test_time)\n",
        "\n",
        "# compute the performance measures\n",
        "score1 = metrics.accuracy_score(test_y, y_pred)\n",
        "score2 = metrics.f1_score(test_y, y_pred,average='macro')\n",
        "score3 = metrics.precision_score(test_y, y_pred, average='macro')\n",
        "score4 = metrics.recall_score(test_y, y_pred, average='macro')\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "print(\"precision:   %0.3f\" % score3)\n",
        "print(\"recall:   %0.3f\" % score4)\n",
        "print(\"f1:   %0.3f\" % score2)\n",
        "\n",
        "print(metrics.classification_report(test_y, y_pred,\n",
        "                                            target_names=['racism', 'sexism', 'neither']))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f796cc8c",
      "metadata": {
        "id": "f796cc8c",
        "outputId": "047471e2-87d2-4393-acb1-ef346855597a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Support Vector Machine : \n",
            "\n",
            "accuracy:   0.758\n",
            "precision:   0.792\n",
            "recall:   0.758\n",
            "f1:   0.763\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      racism       0.89      0.77      0.83       395\n",
            "      sexism       0.87      0.66      0.75       396\n",
            "     neither       0.61      0.84      0.71       395\n",
            "\n",
            "    accuracy                           0.76      1186\n",
            "   macro avg       0.79      0.76      0.76      1186\n",
            "weighted avg       0.79      0.76      0.76      1186\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clf = SVC(C=100, kernel='rbf', gamma = 0.001).fit(X_train_tfidf, train_y)\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "print(\"Support Vector Machine : \\n\")\n",
        "\n",
        "score1 = metrics.accuracy_score(test_y, y_pred)\n",
        "score2 = metrics.f1_score(test_y, y_pred,average='macro')\n",
        "score3 = metrics.precision_score(test_y, y_pred, average='macro')\n",
        "score4 = metrics.recall_score(test_y, y_pred, average='macro')\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "print(\"precision:   %0.3f\" % score3)\n",
        "print(\"recall:   %0.3f\" % score4)\n",
        "print(\"f1:   %0.3f\" % score2)\n",
        "\n",
        "print(metrics.classification_report(test_y, y_pred,\n",
        "                                            target_names=['racism', 'sexism', 'neither']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dda0263",
      "metadata": {
        "id": "2dda0263",
        "outputId": "fa52f63e-6527-4f95-e27d-ddff7b8aca46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree : \n",
            "\n",
            "accuracy:   0.714\n",
            "precision:   0.722\n",
            "recall:   0.714\n",
            "f1:   0.716\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      racism       0.81      0.78      0.79       395\n",
            "      sexism       0.75      0.67      0.71       396\n",
            "     neither       0.60      0.69      0.65       395\n",
            "\n",
            "    accuracy                           0.71      1186\n",
            "   macro avg       0.72      0.71      0.72      1186\n",
            "weighted avg       0.72      0.71      0.72      1186\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train_tfidf,train_y)\n",
        "print(\"Decision Tree : \\n\")\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "\n",
        "score1 = metrics.accuracy_score(test_y, y_pred)\n",
        "score2 = metrics.f1_score(test_y, y_pred,average='macro')\n",
        "score3 = metrics.precision_score(test_y, y_pred, average='macro')\n",
        "score4 = metrics.recall_score(test_y, y_pred, average='macro')\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "print(\"precision:   %0.3f\" % score3)\n",
        "print(\"recall:   %0.3f\" % score4)\n",
        "print(\"f1:   %0.3f\" % score2)\n",
        "\n",
        "print(metrics.classification_report(test_y, y_pred,\n",
        "                                            target_names=['racism', 'sexism', 'neither']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "444d987d",
      "metadata": {
        "id": "444d987d",
        "outputId": "b4e84436-e2b3-48d6-9b67-884bd82e1cb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Classifier : \n",
            "\n",
            "accuracy:   0.749\n",
            "precision:   0.782\n",
            "recall:   0.749\n",
            "f1:   0.751\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      racism       0.85      0.82      0.84       395\n",
            "      sexism       0.89      0.61      0.72       396\n",
            "     neither       0.60      0.82      0.69       395\n",
            "\n",
            "    accuracy                           0.75      1186\n",
            "   macro avg       0.78      0.75      0.75      1186\n",
            "weighted avg       0.78      0.75      0.75      1186\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clf = RandomForestClassifier(n_estimators = 100)\n",
        "\n",
        "clf.fit(X_train_tfidf, train_y)\n",
        "\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Random Forest Classifier : \\n\")\n",
        "\n",
        "score1 = metrics.accuracy_score(test_y, y_pred)\n",
        "score2 = metrics.f1_score(test_y, y_pred,average='macro')\n",
        "score3 = metrics.precision_score(test_y, y_pred, average='macro')\n",
        "score4 = metrics.recall_score(test_y, y_pred, average='macro')\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "print(\"precision:   %0.3f\" % score3)\n",
        "print(\"recall:   %0.3f\" % score4)\n",
        "print(\"f1:   %0.3f\" % score2)\n",
        "\n",
        "print(metrics.classification_report(test_y, y_pred,\n",
        "                                            target_names=['racism', 'sexism', 'neither']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f983fd42",
      "metadata": {
        "id": "f983fd42",
        "outputId": "60ee2a49-268b-499a-fd10-d5225f33aeb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression : \n",
            "\n",
            "accuracy:   0.788\n",
            "precision:   0.797\n",
            "recall:   0.788\n",
            "f1:   0.790\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      racism       0.86      0.86      0.86       395\n",
            "      sexism       0.85      0.73      0.78       396\n",
            "     neither       0.68      0.77      0.72       395\n",
            "\n",
            "    accuracy                           0.79      1186\n",
            "   macro avg       0.80      0.79      0.79      1186\n",
            "weighted avg       0.80      0.79      0.79      1186\n",
            "\n"
          ]
        }
      ],
      "source": [
        "logreg = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# fit the model with data\n",
        "logreg.fit(X_train_tfidf,train_y)\n",
        "\n",
        "y_pred=logreg.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Logistic Regression : \\n\")\n",
        "\n",
        "score1 = metrics.accuracy_score(test_y, y_pred)\n",
        "score2 = metrics.f1_score(test_y, y_pred,average='macro')\n",
        "score3 = metrics.precision_score(test_y, y_pred, average='macro')\n",
        "score4 = metrics.recall_score(test_y, y_pred, average='macro')\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "print(\"precision:   %0.3f\" % score3)\n",
        "print(\"recall:   %0.3f\" % score4)\n",
        "print(\"f1:   %0.3f\" % score2)\n",
        "\n",
        "print(metrics.classification_report(test_y, y_pred,\n",
        "                                            target_names=['racism', 'sexism', 'neither']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa3c96c4",
      "metadata": {
        "id": "aa3c96c4",
        "outputId": "ebcbdb80-625a-436a-f67a-0af7c4919881"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K Nearest Neighbors : \n",
            "\n",
            "accuracy:   0.387\n",
            "precision:   0.677\n",
            "recall:   0.387\n",
            "f1:   0.280\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      racism       0.93      0.04      0.07       395\n",
            "      sexism       0.74      0.15      0.26       396\n",
            "     neither       0.35      0.97      0.52       395\n",
            "\n",
            "    accuracy                           0.39      1186\n",
            "   macro avg       0.68      0.39      0.28      1186\n",
            "weighted avg       0.68      0.39      0.28      1186\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\nabil\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
          ]
        }
      ],
      "source": [
        "model = KNeighborsClassifier(n_neighbors=6)\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(X_train_tfidf,train_y)\n",
        "\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "print(\"K Nearest Neighbors : \\n\")\n",
        "\n",
        "score1 = metrics.accuracy_score(test_y, y_pred)\n",
        "score2 = metrics.f1_score(test_y, y_pred,average='macro')\n",
        "score3 = metrics.precision_score(test_y, y_pred, average='macro')\n",
        "score4 = metrics.recall_score(test_y, y_pred, average='macro')\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "print(\"precision:   %0.3f\" % score3)\n",
        "print(\"recall:   %0.3f\" % score4)\n",
        "print(\"f1:   %0.3f\" % score2)\n",
        "\n",
        "print(metrics.classification_report(test_y, y_pred,\n",
        "                                            target_names=['racism', 'sexism', 'neither']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b689cefe",
      "metadata": {
        "id": "b689cefe"
      },
      "source": [
        "# OVERSAMPLED DATA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bac4ec54",
      "metadata": {
        "id": "bac4ec54"
      },
      "outputs": [],
      "source": [
        "df_1 = c1.sample(class_3, replace=True)\n",
        "df_2_over = c2.sample(class_3, replace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "640f00f6",
      "metadata": {
        "id": "640f00f6",
        "outputId": "e191b8a3-3d15-4f0a-b47e-e5babc28f190"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11501"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7ccf088",
      "metadata": {
        "id": "b7ccf088"
      },
      "outputs": [],
      "source": [
        "\n",
        "oversampled_df = pd.concat([c3,df_1,df_2_over], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e3cf5eb",
      "metadata": {
        "id": "9e3cf5eb",
        "outputId": "601b551a-524e-4af9-8db5-63e952bf2823"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2    11501\n",
              "0    11501\n",
              "1    11501\n",
              "Name: Annotation, dtype: int64"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "oversampled_df[\"Annotation\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d07f5b6d",
      "metadata": {
        "id": "d07f5b6d",
        "outputId": "a9123d58-66f7-4970-9db7-0e29bbd4b21f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Annotation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5406</th>\n",
              "      <td>Someone is going home #mkr ...that obviously cannot cook</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5407</th>\n",
              "      <td>They didn t even wash the chicken   #MKR</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5408</th>\n",
              "      <td>#MKR Is honestly so fucking staged. The most over rated show after #ImACelebrityAU #MKR2015</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5409</th>\n",
              "      <td>Can someone smash that bottle of Rose  amp  Lime Cordial over Drasko s head please #MKR</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5410</th>\n",
              "      <td>Will someone pls assist Colin in the washing of his hair. Sorry Colin, big fan but pls... Some shampoo mate  #mkr</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5015</th>\n",
              "      <td>There are far more bigger problems than sexism out there in the world, I m not sexist and none of my friends are either</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4239</th>\n",
              "      <td>xbox s were designed for boys and make up was designed for girls, get the idea #notsexist #promise #lol</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2961</th>\n",
              "      <td>Opt in solves these problems.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2261</th>\n",
              "      <td>#MKR Tart. Lol.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3332</th>\n",
              "      <td>Never heard that before.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34503 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                             text  \\\n",
              "5406                                                                   Someone is going home #mkr ...that obviously cannot cook     \n",
              "5407                                                                                     They didn t even wash the chicken   #MKR   \n",
              "5408                                  #MKR Is honestly so fucking staged. The most over rated show after #ImACelebrityAU #MKR2015   \n",
              "5409                                      Can someone smash that bottle of Rose  amp  Lime Cordial over Drasko s head please #MKR   \n",
              "5410            Will someone pls assist Colin in the washing of his hair. Sorry Colin, big fan but pls... Some shampoo mate  #mkr   \n",
              "...                                                                                                                           ...   \n",
              "5015      There are far more bigger problems than sexism out there in the world, I m not sexist and none of my friends are either   \n",
              "4239                      xbox s were designed for boys and make up was designed for girls, get the idea #notsexist #promise #lol   \n",
              "2961                                                                                                Opt in solves these problems.   \n",
              "2261                                                                                                              #MKR Tart. Lol.   \n",
              "3332                                                                                                     Never heard that before.   \n",
              "\n",
              "     Annotation  \n",
              "5406          2  \n",
              "5407          2  \n",
              "5408          2  \n",
              "5409          2  \n",
              "5410          2  \n",
              "...         ...  \n",
              "5015          1  \n",
              "4239          1  \n",
              "2961          1  \n",
              "2261          1  \n",
              "3332          1  \n",
              "\n",
              "[34503 rows x 2 columns]"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "oversampled_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61eef1d7",
      "metadata": {
        "id": "61eef1d7"
      },
      "outputs": [],
      "source": [
        "train_X,test_X, train_y, test_y = train_test_split(oversampled_df['text'], oversampled_df['Annotation'],\n",
        "                                                   test_size = 0.2, random_state = 10, stratify = oversampled_df['Annotation'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c091302",
      "metadata": {
        "id": "3c091302",
        "outputId": "c879eac5-94e8-4b17-b413-bb6a3d46dc1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time taken to extract features from training data : 1.858445 seconds\n",
            "n_samples: 27602, n_features: 252252\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\nabil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "t = time()\n",
        "# tf:\n",
        "# tfidf_vectorizer = CountVectorizer()\n",
        "\n",
        "# tfidf:\n",
        "# tfidf_vectorizer = TfidfVectorizer(sublinear_tf = True, max_df = 0.5, stop_words= 'english')\n",
        "\n",
        "# uni-gram:\n",
        "# tfidf_vectorizer = CountVectorizer(ngram_range=(1,1),token_pattern=r'\\b\\w+\\b', min_df=1)\n",
        "\n",
        "# bi-gram:\n",
        "# tfidf_vectorizer = CountVectorizer(ngram_range=(2,2),token_pattern=r'\\b\\w+\\b', min_df=1)\n",
        "\n",
        "# tri-gram:\n",
        "# tfidf_vectorizer = CountVectorizer(ngram_range=(3,3),token_pattern=r'\\b\\w+\\b', min_df=1)\n",
        "\n",
        "# uni-gram & bi-gram:\n",
        "# tfidf_vectorizer = CountVectorizer(ngram_range=(1,2),token_pattern=r'\\b\\w+\\b', min_df=1)\n",
        "\n",
        "# uni-gram,bi-gram & tri-gram:\n",
        "tfidf_vectorizer = CountVectorizer(ngram_range=(1,3),token_pattern=r'\\b\\w+\\b', min_df=1)\n",
        "\n",
        "\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_X)\n",
        "vocabulary = tfidf_vectorizer.get_feature_names()\n",
        "\n",
        "duration = time() - t\n",
        "print(\"Time taken to extract features from training data : %f seconds\" % (duration))\n",
        "print(\"n_samples: %d, n_features: %d\" % X_train_tfidf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12e3acd1",
      "metadata": {
        "id": "12e3acd1",
        "outputId": "2ac489cc-751d-43aa-d912-ab143504e903"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time taken to extract features from test data : 0.245707 seconds\n",
            "n_samples: 6901, n_features: 252252\n"
          ]
        }
      ],
      "source": [
        "t = time()\n",
        "X_test_tfidf = tfidf_vectorizer.transform(test_X)\n",
        "\n",
        "duration = time() - t\n",
        "print(\"Time taken to extract features from test data : %f seconds\" % (duration))\n",
        "print(\"n_samples: %d, n_features: %d\" % X_test_tfidf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9024761",
      "metadata": {
        "id": "c9024761",
        "outputId": "916a93b4-1643-427d-fbaa-71ab1b305ae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train time: 0.068s\n"
          ]
        }
      ],
      "source": [
        "t = time()\n",
        "\n",
        "naive_bayes_classifier = MultinomialNB()\n",
        "naive_bayes_classifier.fit(X_train_tfidf, train_y)\n",
        "\n",
        "training_time = time() - t\n",
        "print(\"train time: %0.3fs\" % training_time)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e3edb96",
      "metadata": {
        "id": "8e3edb96",
        "outputId": "516361c6-dd8f-4489-c0cd-0b6d3f136803"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes : \n",
            "\n",
            "accuracy:   0.888\n",
            "precision:   0.899\n",
            "recall:   0.888\n",
            "f1:   0.882\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      racism       0.85      1.00      0.92      2300\n",
            "      sexism       0.87      0.98      0.92      2301\n",
            "     neither       0.98      0.69      0.81      2300\n",
            "\n",
            "    accuracy                           0.89      6901\n",
            "   macro avg       0.90      0.89      0.88      6901\n",
            "weighted avg       0.90      0.89      0.88      6901\n",
            "\n"
          ]
        }
      ],
      "source": [
        "t = time()\n",
        "y_pred = naive_bayes_classifier.predict(X_test_tfidf)\n",
        "print(\"Naive Bayes : \\n\")\n",
        "test_time = time() - t\n",
        "# print(\"test time:  %0.3fs\" % test_time)\n",
        "\n",
        "# compute the performance measures\n",
        "score1 = metrics.accuracy_score(test_y, y_pred)\n",
        "score2 = metrics.f1_score(test_y, y_pred,average='macro')\n",
        "score3 = metrics.precision_score(test_y, y_pred, average='macro')\n",
        "score4 = metrics.recall_score(test_y, y_pred, average='macro')\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "print(\"precision:   %0.3f\" % score3)\n",
        "print(\"recall:   %0.3f\" % score4)\n",
        "print(\"f1:   %0.3f\" % score2)\n",
        "\n",
        "print(metrics.classification_report(test_y, y_pred,\n",
        "                                            target_names=['racism', 'sexism', 'neither']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9cb3d82",
      "metadata": {
        "id": "d9cb3d82",
        "outputId": "d48957b3-4139-44ae-9397-9308bfe48d78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Support Vector Machine : \n",
            "\n",
            "accuracy:   0.962\n",
            "precision:   0.962\n",
            "recall:   0.962\n",
            "f1:   0.961\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      racism       0.98      1.00      0.99      2300\n",
            "      sexism       0.95      0.96      0.96      2301\n",
            "     neither       0.96      0.92      0.94      2300\n",
            "\n",
            "    accuracy                           0.96      6901\n",
            "   macro avg       0.96      0.96      0.96      6901\n",
            "weighted avg       0.96      0.96      0.96      6901\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clf = SVC(C=100, kernel='rbf', gamma = 0.001).fit(X_train_tfidf, train_y)\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "print(\"Support Vector Machine : \\n\")\n",
        "\n",
        "score1 = metrics.accuracy_score(test_y, y_pred)\n",
        "score2 = metrics.f1_score(test_y, y_pred,average='macro')\n",
        "score3 = metrics.precision_score(test_y, y_pred, average='macro')\n",
        "score4 = metrics.recall_score(test_y, y_pred, average='macro')\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "print(\"precision:   %0.3f\" % score3)\n",
        "print(\"recall:   %0.3f\" % score4)\n",
        "print(\"f1:   %0.3f\" % score2)\n",
        "\n",
        "print(metrics.classification_report(test_y, y_pred,\n",
        "                                            target_names=['racism', 'sexism', 'neither']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14ea485b",
      "metadata": {
        "id": "14ea485b",
        "outputId": "efac7885-4a56-4b8f-decf-55169e761b0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree : \n",
            "\n",
            "accuracy:   0.925\n",
            "precision:   0.928\n",
            "recall:   0.925\n",
            "f1:   0.923\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      racism       0.92      1.00      0.96      2300\n",
            "      sexism       0.89      0.97      0.93      2301\n",
            "     neither       0.97      0.81      0.88      2300\n",
            "\n",
            "    accuracy                           0.93      6901\n",
            "   macro avg       0.93      0.93      0.92      6901\n",
            "weighted avg       0.93      0.93      0.92      6901\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train_tfidf,train_y)\n",
        "print(\"Decision Tree : \\n\")\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "\n",
        "score1 = metrics.accuracy_score(test_y, y_pred)\n",
        "score2 = metrics.f1_score(test_y, y_pred,average='macro')\n",
        "score3 = metrics.precision_score(test_y, y_pred, average='macro')\n",
        "score4 = metrics.recall_score(test_y, y_pred, average='macro')\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "print(\"precision:   %0.3f\" % score3)\n",
        "print(\"recall:   %0.3f\" % score4)\n",
        "print(\"f1:   %0.3f\" % score2)\n",
        "\n",
        "print(metrics.classification_report(test_y, y_pred,\n",
        "                                            target_names=['racism', 'sexism', 'neither']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9602fd3b",
      "metadata": {
        "id": "9602fd3b",
        "outputId": "ff75796b-421e-482c-c825-33ef0fa7969e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Classifier : \n",
            "\n",
            "accuracy:   0.970\n",
            "precision:   0.969\n",
            "recall:   0.970\n",
            "f1:   0.969\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      racism       0.98      1.00      0.99      2300\n",
            "      sexism       0.97      0.96      0.97      2301\n",
            "     neither       0.96      0.95      0.95      2300\n",
            "\n",
            "    accuracy                           0.97      6901\n",
            "   macro avg       0.97      0.97      0.97      6901\n",
            "weighted avg       0.97      0.97      0.97      6901\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clf = RandomForestClassifier(n_estimators = 100)\n",
        "\n",
        "clf.fit(X_train_tfidf, train_y)\n",
        "\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Random Forest Classifier : \\n\")\n",
        "\n",
        "score1 = metrics.accuracy_score(test_y, y_pred)\n",
        "score2 = metrics.f1_score(test_y, y_pred,average='macro')\n",
        "score3 = metrics.precision_score(test_y, y_pred, average='macro')\n",
        "score4 = metrics.recall_score(test_y, y_pred, average='macro')\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "print(\"precision:   %0.3f\" % score3)\n",
        "print(\"recall:   %0.3f\" % score4)\n",
        "print(\"f1:   %0.3f\" % score2)\n",
        "\n",
        "print(metrics.classification_report(test_y, y_pred,\n",
        "                                            target_names=['racism', 'sexism', 'neither']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a44044b8",
      "metadata": {
        "id": "a44044b8",
        "outputId": "c63f1166-35aa-4661-f4fe-8fe3250917f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression : \n",
            "\n",
            "accuracy:   0.958\n",
            "precision:   0.958\n",
            "recall:   0.958\n",
            "f1:   0.958\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      racism       0.96      1.00      0.98      2300\n",
            "      sexism       0.95      0.97      0.96      2301\n",
            "     neither       0.97      0.90      0.93      2300\n",
            "\n",
            "    accuracy                           0.96      6901\n",
            "   macro avg       0.96      0.96      0.96      6901\n",
            "weighted avg       0.96      0.96      0.96      6901\n",
            "\n"
          ]
        }
      ],
      "source": [
        "logreg = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# fit the model with data\n",
        "logreg.fit(X_train_tfidf,train_y)\n",
        "\n",
        "y_pred=logreg.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Logistic Regression : \\n\")\n",
        "\n",
        "score1 = metrics.accuracy_score(test_y, y_pred)\n",
        "score2 = metrics.f1_score(test_y, y_pred,average='macro')\n",
        "score3 = metrics.precision_score(test_y, y_pred, average='macro')\n",
        "score4 = metrics.recall_score(test_y, y_pred, average='macro')\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "print(\"precision:   %0.3f\" % score3)\n",
        "print(\"recall:   %0.3f\" % score4)\n",
        "print(\"f1:   %0.3f\" % score2)\n",
        "\n",
        "print(metrics.classification_report(test_y, y_pred,\n",
        "                                            target_names=['racism', 'sexism', 'neither']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b798d49",
      "metadata": {
        "id": "3b798d49",
        "outputId": "3f973a20-9db7-438e-8576-78ef7538e17f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\nabil\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K Nearest Neighbors : \n",
            "\n",
            "accuracy:   0.907\n",
            "precision:   0.910\n",
            "recall:   0.907\n",
            "f1:   0.908\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      racism       0.99      0.97      0.98      2300\n",
            "      sexism       0.91      0.84      0.87      2301\n",
            "     neither       0.83      0.91      0.87      2300\n",
            "\n",
            "    accuracy                           0.91      6901\n",
            "   macro avg       0.91      0.91      0.91      6901\n",
            "weighted avg       0.91      0.91      0.91      6901\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(X_train_tfidf,train_y)\n",
        "\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "print(\"K Nearest Neighbors : \\n\")\n",
        "\n",
        "score1 = metrics.accuracy_score(test_y, y_pred)\n",
        "score2 = metrics.f1_score(test_y, y_pred,average='macro')\n",
        "score3 = metrics.precision_score(test_y, y_pred, average='macro')\n",
        "score4 = metrics.recall_score(test_y, y_pred, average='macro')\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "print(\"precision:   %0.3f\" % score3)\n",
        "print(\"recall:   %0.3f\" % score4)\n",
        "print(\"f1:   %0.3f\" % score2)\n",
        "\n",
        "print(metrics.classification_report(test_y, y_pred,\n",
        "                                            target_names=['racism', 'sexism', 'neither']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e55213b6",
      "metadata": {
        "id": "e55213b6"
      },
      "outputs": [],
      "source": [
        "duplicate = oversampled_df[oversampled_df.duplicated()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d33d7f57",
      "metadata": {
        "id": "d33d7f57",
        "outputId": "20425a99-aac7-4550-d99d-e752d0740b4f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Annotation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3106</th>\n",
              "      <td>#QuestionsForMen Are you aware that feminism is teaching women that men cannot experience sexism or discrimination  ht</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2878</th>\n",
              "      <td>40 year old woman marries herself after she can t find Mr. Right, goes on honeymoon to Dubai lollol omg stop</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5019</th>\n",
              "      <td>your right im a wanker. But I don t even have enough space in five tweets to point out how much of a cu</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4321</th>\n",
              "      <td>I m not sexist but fuck me half of the women yids on Twitter are fucking clueless</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2082</th>\n",
              "      <td>#MKR anyone can cook from a can girls.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2764</th>\n",
              "      <td>Why don t the like me Andre   #mkr. #cuntfacebitch</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4239</th>\n",
              "      <td>xbox s were designed for boys and make up was designed for girls, get the idea #notsexist #promise #lol</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2961</th>\n",
              "      <td>Opt in solves these problems.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2261</th>\n",
              "      <td>#MKR Tart. Lol.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3332</th>\n",
              "      <td>Never heard that before.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8246 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                             text  \\\n",
              "3106      #QuestionsForMen Are you aware that feminism is teaching women that men cannot experience sexism or discrimination  ht    \n",
              "2878              40 year old woman marries herself after she can t find Mr. Right, goes on honeymoon to Dubai lollol omg stop      \n",
              "5019                     your right im a wanker. But I don t even have enough space in five tweets to point out how much of a cu    \n",
              "4321                                            I m not sexist but fuck me half of the women yids on Twitter are fucking clueless   \n",
              "2082                                                                                       #MKR anyone can cook from a can girls.   \n",
              "...                                                                                                                           ...   \n",
              "2764                                                                         Why don t the like me Andre   #mkr. #cuntfacebitch     \n",
              "4239                      xbox s were designed for boys and make up was designed for girls, get the idea #notsexist #promise #lol   \n",
              "2961                                                                                                Opt in solves these problems.   \n",
              "2261                                                                                                              #MKR Tart. Lol.   \n",
              "3332                                                                                                     Never heard that before.   \n",
              "\n",
              "     Annotation  \n",
              "3106          1  \n",
              "2878          1  \n",
              "5019          1  \n",
              "4321          1  \n",
              "2082          1  \n",
              "...         ...  \n",
              "2764          1  \n",
              "4239          1  \n",
              "2961          1  \n",
              "2261          1  \n",
              "3332          1  \n",
              "\n",
              "[8246 rows x 2 columns]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "duplicate[duplicate[\"Annotation\"]=='1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0cb013c",
      "metadata": {
        "id": "f0cb013c",
        "outputId": "292281af-4f1f-4800-c0b3-eac5c0bd4f98"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Annotation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So Drasko just said he was impressed the girls cooked half a chicken.. They cooked a whole one  #MKR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Drasko they didn t cook half a bird you idiot #mkr</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hopefully someone cooks Drasko in the next ep of #MKR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>of course you were born in serbia...you re as fucked as A Serbian Film #MKR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>These girls are the equivalent of the irritating Asian girls a couple years ago. Well done, 7. #MKR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1971</th>\n",
              "      <td>Drasko they didn t cook half a bird you idiot #mkr</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1972</th>\n",
              "      <td>Hopefully someone cooks Drasko in the next ep of #MKR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1973</th>\n",
              "      <td>#MKR  Lost the plot - where s the big Texan with the elephant sized steaks that they all have for brekkie</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1974</th>\n",
              "      <td>It hasn t been a good few weeks for #ISIS. A new front has opened up in #Sinjar and they re about to lose the battle f</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1975</th>\n",
              "      <td>Charlie Hebdo  editor killed in Paris terror attack built career on defiance</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1976 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                             text  \\\n",
              "0                            So Drasko just said he was impressed the girls cooked half a chicken.. They cooked a whole one  #MKR   \n",
              "1                                                                              Drasko they didn t cook half a bird you idiot #mkr   \n",
              "2                                                                           Hopefully someone cooks Drasko in the next ep of #MKR   \n",
              "3                                                     of course you were born in serbia...you re as fucked as A Serbian Film #MKR   \n",
              "4                             These girls are the equivalent of the irritating Asian girls a couple years ago. Well done, 7. #MKR   \n",
              "...                                                                                                                           ...   \n",
              "1971                                                                           Drasko they didn t cook half a bird you idiot #mkr   \n",
              "1972                                                                        Hopefully someone cooks Drasko in the next ep of #MKR   \n",
              "1973                  #MKR  Lost the plot - where s the big Texan with the elephant sized steaks that they all have for brekkie     \n",
              "1974      It hasn t been a good few weeks for #ISIS. A new front has opened up in #Sinjar and they re about to lose the battle f    \n",
              "1975                                               Charlie Hebdo  editor killed in Paris terror attack built career on defiance     \n",
              "\n",
              "     Annotation  \n",
              "0             0  \n",
              "1             0  \n",
              "2             0  \n",
              "3             0  \n",
              "4             0  \n",
              "...         ...  \n",
              "1971          0  \n",
              "1972          0  \n",
              "1973          0  \n",
              "1974          0  \n",
              "1975          0  \n",
              "\n",
              "[1976 rows x 2 columns]"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final[df_final[\"Annotation\"]=='0']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1bdc639",
      "metadata": {
        "id": "a1bdc639",
        "outputId": "128f0696-4948-4904-8702-967d9d8600f0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Annotation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5406</th>\n",
              "      <td>Someone is going home #mkr ...that obviously cannot cook</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5407</th>\n",
              "      <td>They didn t even wash the chicken   #MKR</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5408</th>\n",
              "      <td>#MKR Is honestly so fucking staged. The most over rated show after #ImACelebrityAU #MKR2015</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5409</th>\n",
              "      <td>Can someone smash that bottle of Rose  amp  Lime Cordial over Drasko s head please #MKR</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5410</th>\n",
              "      <td>Will someone pls assist Colin in the washing of his hair. Sorry Colin, big fan but pls... Some shampoo mate  #mkr</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16902</th>\n",
              "      <td>BillSpindle: It s all about power at the top, but for fighters on the ground #Tikrit is religious war on both sides</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16903</th>\n",
              "      <td>Iraq: #ISIS sets off 21 car bombs in Anbar   as usual, randomly killing  amp  maiming innocents.   htt</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16904</th>\n",
              "      <td>DEAR STATE DEPA MENT: WHERE IS HILLARY CLINTON S OF-109 FORM   #HillaryEmail #tcot #PJNET</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16905</th>\n",
              "      <td>Let s go</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16906</th>\n",
              "      <td></td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11501 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                              text  \\\n",
              "5406                                                                    Someone is going home #mkr ...that obviously cannot cook     \n",
              "5407                                                                                      They didn t even wash the chicken   #MKR   \n",
              "5408                                   #MKR Is honestly so fucking staged. The most over rated show after #ImACelebrityAU #MKR2015   \n",
              "5409                                       Can someone smash that bottle of Rose  amp  Lime Cordial over Drasko s head please #MKR   \n",
              "5410             Will someone pls assist Colin in the washing of his hair. Sorry Colin, big fan but pls... Some shampoo mate  #mkr   \n",
              "...                                                                                                                            ...   \n",
              "16902        BillSpindle: It s all about power at the top, but for fighters on the ground #Tikrit is religious war on both sides     \n",
              "16903                      Iraq: #ISIS sets off 21 car bombs in Anbar   as usual, randomly killing  amp  maiming innocents.   htt    \n",
              "16904                                 DEAR STATE DEPA MENT: WHERE IS HILLARY CLINTON S OF-109 FORM   #HillaryEmail #tcot #PJNET      \n",
              "16905                                                                                                            Let s go            \n",
              "16906                                                                                                                                \n",
              "\n",
              "      Annotation  \n",
              "5406           2  \n",
              "5407           2  \n",
              "5408           2  \n",
              "5409           2  \n",
              "5410           2  \n",
              "...          ...  \n",
              "16902          2  \n",
              "16903          2  \n",
              "16904          2  \n",
              "16905          2  \n",
              "16906          2  \n",
              "\n",
              "[11501 rows x 2 columns]"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final[df_final[\"Annotation\"]=='2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06c5d17d",
      "metadata": {
        "id": "06c5d17d",
        "outputId": "990faf0e-c181-4c4c-d8fe-b4eb1b859680"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Annotation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1976</th>\n",
              "      <td>These two are revolting #MKR #MKR2015</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1977</th>\n",
              "      <td>#katieandnikki stop calling yourselves pretty and hot..you re not and saying it a million times doesn t make you either...STFU #MKR</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1978</th>\n",
              "      <td>If   keep these girls in the comp, which I suspect they will, I ll never watch #MKR again.\\n\\nSO SO SO Rigged.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1979</th>\n",
              "      <td>The menus look like they were made by a 5 year old little girl...in this case just the mental age of a 5 year old girl I guess #MKR</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980</th>\n",
              "      <td>Wish these blondes were in that How To Get Away With Murder show....#MKR</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5401</th>\n",
              "      <td>Katie and Nikki, smug, vacuous, condescending, putrid, self congratulatory and bland. There. #MKR</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5402</th>\n",
              "      <td>I can barely watch the #MKR episode of Katie and Nikki or whatever. Like my skin is crawling. They have thattt many tickets on themselves</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5403</th>\n",
              "      <td>Really    Really    Another round   #MKR those butcher promo girls better be nice to Sheri and Emilie.  Yes OR else</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5404</th>\n",
              "      <td>#MKR you d think in her downtime Annie would have paid Napol√©on Perdis a visit and learnt not to use the same coloured blush as your hair...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5405</th>\n",
              "      <td>Gay fianc√© is not going to cope being away from the fresh meat #MKR</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3430 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                              text  \\\n",
              "1976                                                                                                         These two are revolting #MKR #MKR2015   \n",
              "1977           #katieandnikki stop calling yourselves pretty and hot..you re not and saying it a million times doesn t make you either...STFU #MKR   \n",
              "1978                                If   keep these girls in the comp, which I suspect they will, I ll never watch #MKR again.\\n\\nSO SO SO Rigged.   \n",
              "1979           The menus look like they were made by a 5 year old little girl...in this case just the mental age of a 5 year old girl I guess #MKR   \n",
              "1980                                                                      Wish these blondes were in that How To Get Away With Murder show....#MKR   \n",
              "...                                                                                                                                            ...   \n",
              "5401                                             Katie and Nikki, smug, vacuous, condescending, putrid, self congratulatory and bland. There. #MKR   \n",
              "5402   I can barely watch the #MKR episode of Katie and Nikki or whatever. Like my skin is crawling. They have thattt many tickets on themselves     \n",
              "5403                           Really    Really    Another round   #MKR those butcher promo girls better be nice to Sheri and Emilie.  Yes OR else   \n",
              "5404  #MKR you d think in her downtime Annie would have paid Napol√©on Perdis a visit and learnt not to use the same coloured blush as your hair...   \n",
              "5405                                                                           Gay fianc√© is not going to cope being away from the fresh meat #MKR   \n",
              "\n",
              "     Annotation  \n",
              "1976          1  \n",
              "1977          1  \n",
              "1978          1  \n",
              "1979          1  \n",
              "1980          1  \n",
              "...         ...  \n",
              "5401          1  \n",
              "5402          1  \n",
              "5403          1  \n",
              "5404          1  \n",
              "5405          1  \n",
              "\n",
              "[3430 rows x 2 columns]"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final[df_final[\"Annotation\"]=='1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e75390a",
      "metadata": {
        "id": "1e75390a",
        "outputId": "901cd029-d6aa-4469-e12f-72ff10e23cae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2    11501\n",
              "1     3430\n",
              "0     1976\n",
              "Name: Annotation, dtype: int64"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final[\"Annotation\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5198f441",
      "metadata": {
        "id": "5198f441",
        "outputId": "803cc060-d203-407d-929d-7c4212bcf028"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(16907, 2)"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5474474b",
      "metadata": {
        "id": "5474474b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}