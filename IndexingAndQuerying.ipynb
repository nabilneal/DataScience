{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nabilneal/DataScience/blob/main/IndexingAndQuerying.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eb1c6bf-7b7c-4c9a-b73b-aef38b76ace0",
      "metadata": {
        "id": "3eb1c6bf-7b7c-4c9a-b73b-aef38b76ace0",
        "outputId": "8cfa2b26-18ca-4148-a385-fd2ca3bfdcdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index has been created and saved as ouput.json file\n",
            "Size of the index is 295000 bytes\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import nltk as tk\n",
        "from nltk.corpus import stopwords\n",
        "import json\n",
        "\n",
        "# directory of the documents\n",
        "folder_path = r'documents'\n",
        "\n",
        "# allowing to read the filenames\n",
        "files= os.listdir(folder_path)\n",
        "\n",
        "intList={}\n",
        "\n",
        "# to sort the files, converting into int after trimming the file_name\n",
        "for file in files:\n",
        "\n",
        "    a=file\n",
        "    a=a.replace(\"file_\",\"\")\n",
        "    a=a.replace(\".txt\",\"\")\n",
        "\n",
        "    if a.isdigit():\n",
        "        b=intList.get(file,[])\n",
        "        b.append(int(a))\n",
        "        intList[file]=b\n",
        "\n",
        "\n",
        "sorted_values = sorted(intList.values()) # Sort the values\n",
        "sorted_dict = {}\n",
        "\n",
        "\n",
        "for i in sorted_values:\n",
        "    for k in intList.keys():\n",
        "        if intList[k] == i:\n",
        "            sorted_dict[k] = intList[k]\n",
        "            break\n",
        "\n",
        "# to get the key, which are the filenames\n",
        "def GetKey(val):\n",
        "        for key, value in sorted_dict.items():\n",
        "            if val == value:\n",
        "                return key\n",
        "# print(GetKey([1]))\n",
        "\n",
        "\n",
        "\n",
        "# empty index dictionary for the words and the document ID,\n",
        "# and for Document ID using count to save in the dictionary\n",
        "count=1\n",
        "index= {}\n",
        "for i in sorted_dict.values():\n",
        "\n",
        "#     to get the path and the file name together inorder to open each files\n",
        "    fullname=os. path. join(folder_path, GetKey(i))\n",
        "\n",
        "    with open(fullname,\"r\") as inputfile:\n",
        "#         used tokenizer, stemmer and stop words\n",
        "        content = inputfile.read()\n",
        "        token = tk.word_tokenize(content)\n",
        "        token.sort()\n",
        "        stemmer = tk.stem.PorterStemmer()\n",
        "        stemmed_word = [stemmer.stem(word) for word in token]\n",
        "#         print(stemmed_word)\n",
        "        distinct = []\n",
        "        for word in stemmed_word:\n",
        "            if word not in distinct:\n",
        "                distinct.append(word)\n",
        "#             print(distinct)\n",
        "        nltk_stop= set(stopwords.words('english'))\n",
        "        stop_words = '''...!@#$%^&*(){}[]|._-`/?:;\"'\\,''``~12345678876543+--....'''\n",
        "        text_no_stop = [w for w in distinct if not w.lower() in nltk_stop]\n",
        "        text_no_stop = [char for char in text_no_stop if char not in stop_words]\n",
        "#             print(text_no_stop)\n",
        "\n",
        "#         to save the key(tokenized words) and the corresponding values(document IDs)\n",
        "        for terms in text_no_stop:\n",
        "            postings = index.get(terms,[])\n",
        "            postings.append(count)\n",
        "            index[terms] = postings\n",
        "        count+=1\n",
        "\n",
        "ab = sys.getsizeof(index)\n",
        "\n",
        "# print(index)\n",
        "\n",
        "# Saved the output as json file and counted the size of the index\n",
        "output = os. path. join(folder_path, \"output.json\")\n",
        "with open(output, 'w') as outfile:\n",
        "    json.dump(index, outfile)\n",
        "    print(\"Index has been created and saved as ouput.json file\")\n",
        "    print(\"Size of the index is {} bytes\".format(ab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b80d9f4-a24d-4ced-bdf7-f445e8626230",
      "metadata": {
        "id": "0b80d9f4-a24d-4ced-bdf7-f445e8626230",
        "outputId": "53fbdc16-31a7-44a6-f5f7-9c6bf6ac3fd7"
      },
      "outputs": [
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "Enter a word:  briefly\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Select operation.\n",
            "1.Intersection\n",
            "2.Union\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "Enter choice(1/2):  1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Do you want to add Not operation on the next word?\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "Enter choice(y/n):  n\n",
            "\n",
            "Enter a word:  ddc\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1}\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "Let's do next operation? (y/n):  n\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import nltk as tk\n",
        "import json\n",
        "\n",
        "# Opening the json file to extract the index dictionary\n",
        "folder_path = r'documents'\n",
        "\n",
        "files= os.listdir(folder_path)\n",
        "file = os. path. join(folder_path, \"output.json\")\n",
        "with open(file, mode='r') as infile:\n",
        "    index = json.load(infile)\n",
        "#     print(index)\n",
        "\n",
        "\n",
        "# Operation functions\n",
        "def do_intersection(a,b):\n",
        "    return (a & b)\n",
        "\n",
        "def do_union(a,b):\n",
        "    return (a | b)\n",
        "\n",
        "def do_not(a,b):\n",
        "    return (a - b)\n",
        "\n",
        "# Creating full set for NOT operation\n",
        "R = [*range(1,1461)]\n",
        "allDocu = set(R)\n",
        "\n",
        "\n",
        "# First string input is outside the loop then rest of the inputs will work on loops\n",
        "# using stemmer on the strings and checking if it's inside the index\n",
        "word = input(\"Enter a word: \")\n",
        "porter1 = tk.stem.PorterStemmer()\n",
        "stemmer1=porter1.stem(word)\n",
        "if stemmer1 not in index.keys():\n",
        "    print(\"the word couldn't be found in the index\")\n",
        "else:\n",
        "#     the loop goes on until wrong input is entered or the user wants to end\n",
        "    while True:\n",
        "    # take input from the user\n",
        "        print(\"\\n\\nSelect operation.\")\n",
        "        print(\"1.Intersection\")\n",
        "        print(\"2.Union\")\n",
        "        operation = int(input(\"Enter choice(1/2): \"))\n",
        "        print(\"\\nDo you want to add Not operation on the next word?\")\n",
        "        op_not = input(\"Enter choice(y/n): \")\n",
        "        comparison_word= input(\"\\nEnter a word: \")\n",
        "        porter2 = tk.stem.PorterStemmer()\n",
        "        stemmer2=porter2.stem(comparison_word)\n",
        "        wo = set(index[stemmer1])\n",
        "\n",
        "        if stemmer2 in index.keys():\n",
        "            co_wo = set(index[stemmer2])\n",
        "            if operation == 1 and op_not == \"n\":\n",
        "                a = do_intersection(wo, co_wo)\n",
        "                print(a)\n",
        "            elif operation == 1 and op_not == \"y\":\n",
        "                x = do_not(allDocu,co_wo)\n",
        "                a = do_intersection(wo, x)\n",
        "                print(a)\n",
        "            elif operation == 2 and op_not == \"n\":\n",
        "                a = do_union(wo, co_wo)\n",
        "                print(a)\n",
        "            elif operation == 2 and op_not == \"y\":\n",
        "                x = do_not(allDocu,co_wo)\n",
        "                a = do_union(wo, x)\n",
        "                print(a)\n",
        "            else:\n",
        "                print(\"You did something wrong. try again!\")\n",
        "                break\n",
        "            next_operation = input(\"Let's do next operation? (y/n): \")\n",
        "\n",
        "            if next_operation == \"y\":\n",
        "                wo=a\n",
        "                print(wo)\n",
        "            else:\n",
        "                break\n",
        "        else:\n",
        "            print(\"the word couldn't be found in the index\")\n",
        "            break\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "239c2973-5ac0-4725-b0f9-4670ecae0b54",
      "metadata": {
        "id": "239c2973-5ac0-4725-b0f9-4670ecae0b54"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}